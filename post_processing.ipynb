{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e91243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T20:41:26.879421Z",
     "start_time": "2021-06-08T20:41:26.876140Z"
    }
   },
   "source": [
    "# Under-Representation Bias (w/ Synthetic Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00909876",
   "metadata": {},
   "source": [
    "This notebook recreates the finding that Equalized Odds constrained model can recover from under-representation bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42ced1",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Please run the code block below to install the necessary packages (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a692724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T20:42:02.586362Z",
     "start_time": "2021-06-10T20:42:02.581026Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_curve, auc\n",
    "from collections import Counter\n",
    "\n",
    "import fairlearn\n",
    "from fairlearn.metrics import *\n",
    "from fairlearn.reductions import *\n",
    "from fairlearn.postprocessing import *\n",
    "import aif360\n",
    "\n",
    "import copy, random\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59e303",
   "metadata": {},
   "source": [
    "# Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46dc53-d064-4c1f-8845-891216d77cde",
   "metadata": {},
   "source": [
    "## Parameters (User Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4c1bcf-a112-4a4f-9d02-a6724a2268b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "r is the proportion of training examples in the minority group, \n",
    "\n",
    "which means 1-r is proportion of examples in the majority group\n",
    "\n",
    "eta is the probability of flipping the label\n",
    "\n",
    "n is the number of training examples\n",
    "\n",
    "beta is the probability of keeping a positively labeled example\n",
    "from the minority class\n",
    "\n",
    "NOTE: results can be replicated if and only if the following condition holds:\n",
    "\n",
    "(1-r)(1-2*eta) + r((1-eta)*beta - eta) > 0\n",
    "\n",
    "'''\n",
    "def get_params(r = 1/3, eta = 1/4, n = 2000, beta = 0.5):\n",
    "    return r, eta, n, beta\n",
    "\n",
    "r, eta, n, beta = get_params(r = 1/3, eta = 0, n = 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7d3c98-54c3-4198-9f03-528bebb016cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraint:  0.19999999999999996\n",
      "yes! 0.2 0.4 1.0\n",
      "constraint:  0.18799999999999997\n",
      "yes! 0.2 0.4 0.9\n",
      "constraint:  0.17599999999999996\n",
      "yes! 0.2 0.4 0.8\n",
      "constraint:  0.16399999999999998\n",
      "yes! 0.2 0.4 0.7\n",
      "constraint:  0.15199999999999997\n",
      "yes! 0.2 0.4 0.6\n",
      "constraint:  0.13999999999999996\n",
      "yes! 0.2 0.4 0.5\n",
      "constraint:  0.12799999999999997\n",
      "yes! 0.2 0.4 0.4\n",
      "constraint:  0.11599999999999996\n",
      "yes! 0.2 0.4 0.3\n",
      "constraint:  0.10399999999999997\n",
      "yes! 0.2 0.4 0.2\n",
      "constraint:  0.09199999999999997\n",
      "yes! 0.2 0.4 0.1\n",
      "constraint:  0.07999999999999996\n",
      "yes! 0.2 0.4 0.0\n"
     ]
    }
   ],
   "source": [
    "# check if above constraint holds\n",
    "def check_constraints(r, eta, beta):\n",
    "    first = (1-r)*(1-2*eta)\n",
    "    second = r * ((1-eta)*beta - eta)\n",
    "    res = first + second\n",
    "    print(\"constraint: \", res)\n",
    "    print(\"yes!\", r, eta, beta) if res > 0 else print(\"no\", r, eta, beta)\n",
    "    \n",
    "bias_amts = np.divide(list(range(10, -1, -1)),10)\n",
    "\n",
    "for beta in bias_amts:\n",
    "    check_constraints(r=0.2, eta=0.4, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ebbd2-719c-42d5-8de4-dce388fc0a51",
   "metadata": {},
   "source": [
    "## True Label Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f9b8a4-c293-4c8a-9c8c-72d28f624312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create minority and majority groups\n",
    "def get_cat_features(n, r):\n",
    "    num_minority = int(r * n)\n",
    "    num_majority = n - num_minority\n",
    "    \n",
    "    minority = np.zeros((num_minority, 1))\n",
    "    majority = np.ones((num_majority, 1))\n",
    "    \n",
    "    cat_features = np.vstack((minority, majority))\n",
    "    #np.random.shuffle(cat_features) # this is what causes us to not recover coeffs\n",
    "    \n",
    "    return cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3451925-fd73-48e1-9088-6914aaf5210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return labels from Bayes Optimal Classifier\n",
    "def get_bayes_optimal_labels(features, effect_param, threshold = 0.5):\n",
    "    outcome_continuous = 1/(1+np.exp(-np.matmul(features, effect_param)))\n",
    "    #return outcome_continuous, np.random.binomial(1,outcome_continuous) # bernoulli to simulate LR's probabilistic nature\n",
    "    return outcome_continuous, np.where(outcome_continuous < threshold, 0, 1)\n",
    "\n",
    "# flip labels with probability eta\n",
    "# def flip_labels(df_synthetic, eta):\n",
    "#     labels = df_synthetic['outcome']\n",
    "#     #print('Before:', df_synthetic['outcome'].value_counts())\n",
    "#     num_flipped = 0\n",
    "#     for i in range(len(labels)):\n",
    "#         if random.uniform(0,1) <= eta:\n",
    "#             labels[i] = 1 if labels[i] == 0 else 0\n",
    "#             num_flipped += 1\n",
    "#     df_synthetic['outcome'] = labels\n",
    "#     #print('After:', df_synthetic['outcome'].value_counts())\n",
    "#     #print('Num Flipped: ', num_flipped, \"\\tRate: \", num_flipped / len(df_synthetic))\n",
    "#     return df_synthetic\n",
    "\n",
    "def flip_labels(df_synthetic, eta):\n",
    "    labels = list(df_synthetic['outcome'].values)\n",
    "    #print('Before:', df_synthetic['outcome'].value_counts())\n",
    "    num_flipped = 0\n",
    "    for i in range(len(labels)):\n",
    "        if random.uniform(0,1) <= eta:\n",
    "            labels[i] = 1 if labels[i] == 0 else 0\n",
    "            num_flipped += 1\n",
    "    df_synthetic['outcome_flipped'] = labels\n",
    "    df_synthetic['outcome'] = labels\n",
    "    #print('After:', df_synthetic['outcome'].value_counts())\n",
    "    #print('Num Flipped: ', num_flipped, \"\\tRate: \", num_flipped / len(df_synthetic))\n",
    "    return df_synthetic\n",
    "\n",
    "# use this function to inject eta_maj into both majority and negatively labeled minority samples\n",
    "def flip_labels2(df_majority, eta_maj, df_minority, eta_min, inter = True):\n",
    "    labels_maj = list(df_majority['outcome'].values)\n",
    "    labels_min = list(df_minority['outcome'].values)\n",
    "    \n",
    "    num_flipped_maj = 0\n",
    "    for i in range(len(labels_maj)):\n",
    "        if random.uniform(0,1) <= eta_maj:\n",
    "            labels_maj[i] = 1 if labels_maj[i] == 0 else 0\n",
    "            num_flipped_maj += 1\n",
    "    df_majority['outcome_flipped'] = labels_maj\n",
    "    print('Num Flipped Maj: ', num_flipped_maj, \"\\tRate: \", num_flipped_maj / len(df_majority))\n",
    "    if not inter: df_minority['outcome_flipped'] = labels_min\n",
    "    \n",
    "    if inter:\n",
    "    \n",
    "        #df_majority['diff'] = abs(df_majority['outcome'] - df_majority['outcome_flipped'])\n",
    "        #print(df_minority.groupby('outcome')['diff'].value_counts(normalize=True))\n",
    "\n",
    "        neg = len(df_minority[df_minority['outcome'] == 0])\n",
    "\n",
    "        num_flipped_min = 0\n",
    "        for i in range(len(labels_min)):\n",
    "            if random.uniform(0,1) <= eta_maj and labels_min[i] == 0:\n",
    "                labels_min[i] = 1\n",
    "                num_flipped_min += 1\n",
    "\n",
    "        df_minority['outcome_flipped'] = labels_min\n",
    "        #df_minority['diff'] = abs(df_minority['outcome'] - df_minority['outcome_flipped'])\n",
    "        #print(\"minority\", df_minority.groupby('outcome')['diff'].value_counts(normalize=True))\n",
    "\n",
    "        print('Num Flipped Min Neg: ', num_flipped_min, \"\\tRate: \", num_flipped_min / neg)\n",
    "\n",
    "    df_concat = pd.concat([df_majority, df_minority])\n",
    "    #print(df_majority.shape, df_minority.shape)\n",
    "    #df_concat = pd.DataFrame(np.vstack([df_majority, df_minority]))\n",
    "    #df_concat.columns = ['num1','num2','num3','cat','outcome','outcome_flipped', 'diff']\n",
    "    \n",
    "    #print(\"concat\", df_concat.groupby(['cat','outcome'])['diff'].value_counts(normalize=True))\n",
    "    return df_concat.sample(frac=1, random_state = 42) # permute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582e29cb-af49-436e-89df-b973ab489145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  -0.004799999999999971\n",
      "Num Flipped Maj:  16070 \tRate:  0.40175\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "'''\n",
    "\n",
    "create synthetic data with:\n",
    "    3 numerical features (Gaussian), 1 categorical (sensitive attribute) \n",
    "    logistic outcome model s.t. outcome = Indicator[logit(effect_param*features) >= 0.5]\n",
    "    \n",
    "create minority/majority groups according to r param\n",
    "\n",
    "simulate Bayes Optimal Classifiers for minority and majority\n",
    "\n",
    "flip labels according to eta param\n",
    "\n",
    "ensure equal base rates (proportion of positive examples) across both groups\n",
    "\n",
    "is_exploration is for group-dependent label noise\n",
    "\n",
    "'''\n",
    "\n",
    "def true_label_generation(r, eta, n, maj_means = [0,0,0], is_exploration = False, inter = True):\n",
    "\n",
    "    ''' \n",
    "    delete this variable to allow user to control percentage of positively labeled examples\n",
    "    eg: let outcome_continuous >= 0.2 implies 80% positively labeled samples\n",
    "    '''\n",
    "    # causal effect params\n",
    "    maj_params = [-0.7, 0.5, 1.5]\n",
    "    effect_param_min = [0.5, -0.2, 0.1]\n",
    "    #effect_param_maj = [i + np.random.uniform(low = -1, high = 1) for i in maj_params]\n",
    "    effect_param_maj = maj_params\n",
    "    \n",
    "    num_min = int(n*r)\n",
    "    num_maj = n - num_min\n",
    "\n",
    "    # required: len(cat_probabilities) = n_cat_features\n",
    "    n_cat_features = 2\n",
    "    cat_probabilities = [0.5, 0.5] \n",
    "\n",
    "    # numerical feature params\n",
    "    means = [0, 0, 0]\n",
    "    cov_matrix = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "\n",
    "    # features\n",
    "    cat_features = get_cat_features(r=r, n=n)\n",
    "    \n",
    "    num_features_min = np.random.multivariate_normal(means, cov_matrix, num_min)\n",
    "    #num_features_min = np.random.normal(0, 1, num_min)\n",
    "    num_features_maj = np.random.multivariate_normal(maj_means, cov_matrix, num_maj)\n",
    "    # num_features_maj = np.array([i + np.random.uniform(low = -15, high = 10) for i in num_features_maj])\n",
    "    #num_features_min = np.random.normal(0, 1, num_min)\n",
    "\n",
    "    num_features = np.concatenate((num_features_min, num_features_maj))\n",
    "\n",
    "    # outcomes\n",
    "    outcome_continuous_min, outcome_binary_min = get_bayes_optimal_labels(features=num_features_min, effect_param=effect_param_min, threshold = 0.5)\n",
    "    #outcome_binary_min = np.where(np.matmul(num_features_min, effect_param_min) > 0.5, 1, 0)\n",
    "    outcome_continuous_maj, outcome_binary_maj = get_bayes_optimal_labels(features=num_features_maj, effect_param=effect_param_maj, threshold = 0.5)\n",
    "    #outcome_binary_maj = np.where(np.matmul(num_features_maj, effect_param_maj) > 0.5, 1, 0)\n",
    "    \n",
    "    outcome = np.hstack((outcome_binary_min,outcome_binary_maj)).reshape(n,1)\n",
    "    outcome_continuous = np.hstack((outcome_continuous_min,outcome_continuous_maj)).reshape(n,1)\n",
    "    temp_data = np.hstack((num_features,cat_features, outcome, outcome_continuous))\n",
    "    #print(outcome_continuous)\n",
    "    #print(np.where(outcome_continuous < 0.5, 0, 1))\n",
    "    np.random.shuffle(temp_data) # randomly shuffle the data\n",
    "    \n",
    "    df_synthetic = pd.DataFrame(temp_data)\n",
    "    df_synthetic.columns = ['num1','num2','num3','cat','outcome','outcome_cont']\n",
    "    \n",
    "    outcome_continuous = df_synthetic.outcome_cont\n",
    "    df_synthetic = df_synthetic[['num1','num2','num3','cat','outcome']]\n",
    "    \n",
    "    df_majority = df_synthetic[df_synthetic['cat'] == 1]\n",
    "    df_minority = df_synthetic[df_synthetic['cat'] == 0]\n",
    "    \n",
    "    #print('% Positive Majority: ', df_majority['outcome'].value_counts()[1] / len(df_majority))\n",
    "    #print('\\n% Positive Minority: ', df_minority['outcome'].value_counts()[1] / len(df_minority))\n",
    "    print('Diff: ', df_majority['outcome'].value_counts()[1] / len(df_majority)- df_minority['outcome'].value_counts()[1] / len(df_minority))\n",
    "    #print('\\nTotal: ', df_majority['outcome'].value_counts())\n",
    "    \n",
    "    if inter:\n",
    "        if not is_exploration: \n",
    "            df_synthetic = flip_labels(df_synthetic, eta)\n",
    "        else:\n",
    "            df_synthetic = flip_labels2(df_majority, 0.4, df_minority, 0) # group dependent label noise\n",
    "    else:\n",
    "        df_synthetic = flip_labels2(df_majority, 0.4, df_minority, 0, inter = False) # group dependent label noise\n",
    "\n",
    "    return outcome_continuous, df_synthetic \n",
    "\n",
    "outcome_continuous, df_synthetic = true_label_generation(r=r, eta=eta, n=2*n, maj_means = [0,0,0], is_exploration=True, inter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a36a53-ce4f-4e2f-b11e-9eddb75b7e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat  outcome  diff\n",
      "0.0  0.0      0.0     1.000000\n",
      "     1.0      0.0     1.000000\n",
      "1.0  0.0      0.0     0.597786\n",
      "              1.0     0.402214\n",
      "     1.0      0.0     0.598717\n",
      "              1.0     0.401283\n",
      "Name: diff, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# df_synthetic['diff'] = abs(df_synthetic['outcome'] - df_synthetic['outcome_flipped'])\n",
    "# df_synthetic.groupby(['cat','outcome'])['diff'].value_counts(normalize=True)\n",
    "\n",
    "def check_groups(df):\n",
    "    df = df.copy()\n",
    "    df['diff'] = abs(df['outcome'] - df['outcome_flipped'])\n",
    "    print(df.groupby(['cat','outcome'])['diff'].value_counts(normalize=True))\n",
    "\n",
    "check_groups(df_synthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7fd87-924b-41b0-a505-25cac190e8cd",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d385bc3-625f-4726-a2b3-7dac659fda04",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240d919e-9d87-4429-9f42-e4f2a938fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "df_train = df_synthetic.loc[range(0,int(n/2)), :]\n",
    "# if original dataset has odd number of samples, remove 1 sample to be even\n",
    "if (n % 2 == 1):\n",
    "    df_test = df_synthetic.loc[range(int(n/2)+1, n), :]\n",
    "else:\n",
    "    df_test = df_synthetic.loc[range(int(n/2), n), :]\n",
    "\n",
    "df_fidel = df_synthetic.loc[range(n, len(df_synthetic)),:]\n",
    "outcome_cts = outcome_continuous[n:len(df_synthetic)]\n",
    "    \n",
    "df_test_maj = df_test[df_test['cat'] == 1]\n",
    "df_test_min = df_test[df_test['cat'] == 0]\n",
    "\n",
    "# format data\n",
    "X_true = df_test.iloc[:, :-2].values\n",
    "y_true = df_test.iloc[:, -1].values\n",
    "\n",
    "X_true_maj = df_test_maj.iloc[:, :-2].values\n",
    "y_true_maj = df_test_maj.iloc[:, -1].values\n",
    "X_true_min = df_test_min.iloc[:, :-2].values\n",
    "y_true_min = df_test_min.iloc[:, -1].values\n",
    "\n",
    "sens_attrs_true = [df_test['cat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950918b3",
   "metadata": {},
   "source": [
    "# Bias Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60f7195-a5e7-46d4-9308-65ae9c5c8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement bias\n",
    "def inject_noise_num(df, feature, eps = 1):\n",
    "    for i in range(len(df[feature])):\n",
    "        df[feature].iloc[i] += np.random.normal(0, 1) * eps # standard normal\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a788ace-562a-4256-a853-40db73a61e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attribute': 'num1', 'min': -4.402114371237914, 'max': 3.7684471201461927, '1st Quartile': -0.6724047425981724, '2nd Quartile': -0.00014691158212111068, '3rd Quartile': 0.6614565259816217}\n",
      "{'attribute': 'num1', 'min': -4.402114371237914, 'max': 3.7684471201461927, '1st Quartile': -0.7343612341393261, '2nd Quartile': -0.07489331687491849, '3rd Quartile': 0.5886896612953523}\n"
     ]
    }
   ],
   "source": [
    "from numpy import percentile\n",
    "def under_sample(df_minority_positive, beta):\n",
    "    X_min = df_minority_positive.iloc[:, :].values\n",
    "    \n",
    "    # keep each example with probability beta\n",
    "    num_dropped = 0\n",
    "    for i in range(len(X_min)):\n",
    "        if random.uniform(0,1) > beta:\n",
    "            X_min = np.delete(X_min, 0, axis=0)\n",
    "            num_dropped += 1\n",
    "    #print(\"Total Deleted: \", num_dropped, \"\\t % Deleted: \", num_dropped / len(df_minority_positive))\n",
    "    df_minority_positive = pd.DataFrame(pd.DataFrame(X_min))\n",
    "    df_minority_positive.columns = ['num1','num2','num3','cat','outcome', 'outcome_flipped']\n",
    "    return df_minority_positive\n",
    "\n",
    "\n",
    "def get_biased_data(df_train, beta):\n",
    "    df_majority = df_train[df_train['cat'] == 1]\n",
    "    df_minority = df_train[df_train['cat'] == 0]\n",
    "    \n",
    "    # unfavored group with negative label\n",
    "    df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "    # unfavored group with positive label (preferred)\n",
    "    df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "    \n",
    "    # data frame without positively labeled examples from minority class\n",
    "    df_total = pd.concat([df_majority, df_minority_negative])\n",
    "    \n",
    "    # under-sampling process\n",
    "    df_undersampled = under_sample(df_minority_positive, beta)\n",
    "\n",
    "    # combine undersampled and original favored class to create dataset\n",
    "    df_concat = pd.concat([df_total,df_undersampled])\n",
    "    \n",
    "    return df_concat.sample(frac=1) # permute data\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# representation bias, under-sampling entire minority\n",
    "def get_biased_data(df_train, beta):\n",
    "    df_majority = df_train[df_train['cat'] == 1]\n",
    "    df_minority = df_train[df_train['cat'] == 0]\n",
    "    \n",
    "    # under-sampling process\n",
    "    df_undersampled = under_sample(df_minority, beta)\n",
    "\n",
    "    # combine undersampled and original favored class to create dataset\n",
    "    df_concat = pd.concat([df_majority,df_undersampled])\n",
    "    \n",
    "    return df_concat.sample(frac=1) # permute data\n",
    "'''\n",
    "\n",
    "def get_summary_num(df, feature):\n",
    "    res = dict()\n",
    "    res['attribute'] = feature\n",
    "\n",
    "    data_min, data_max = df[feature].min(), df[feature].max()\n",
    "    res['min'] = data_min\n",
    "    res['max'] = data_max\n",
    "\n",
    "    quartiles = percentile(df[feature], [25,50,75])\n",
    "    res['1st Quartile'] = quartiles[0]\n",
    "    res['2nd Quartile'] = quartiles[1]\n",
    "    res['3rd Quartile'] = quartiles[2]\n",
    "\n",
    "    return res\n",
    "\n",
    "#print(len(df_train[(df_train['cat'] == 0) & (df_train['outcome'] == 1)]))\n",
    "print(get_summary_num(df_train, 'num1'))\n",
    "df_concat = get_biased_data(df_train, 0.5)\n",
    "print(get_summary_num(df_concat, 'num1'))\n",
    "#print(len(df_concat[(df_concat['cat'] == 0) & (df_concat['outcome'] == 1)]))\n",
    "\n",
    "# for fairness measures later\n",
    "df_sens = df_concat['cat']\n",
    "\n",
    "# format data\n",
    "X_bias = df_concat.iloc[:, :-2].values\n",
    "y_bias = df_concat.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "213427a7-8fec-4a2a-a568-439e01b6b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Nil-Jana's Suggestions '''\n",
    "\n",
    "def transform(df, is_test = False, is_train = False):\n",
    "\n",
    "    sens_feat = df['cat'].values\n",
    "    outcome = df['outcome'].values\n",
    "    outcome_flipped = df['outcome_flipped'].values\n",
    "    num_feats = df.iloc[:, :-3].values\n",
    "\n",
    "    trans_feats = [] # x1a - x3a\n",
    "    other_feats = [] # x1(1-a) - x3(1-a)\n",
    "    # -2 for sensitive feature and label\n",
    "    for i in range(len(df.columns) - 3):\n",
    "        num_feat = df.iloc[:, i].values\n",
    "        num_feat_transf = np.multiply(num_feat, sens_feat)\n",
    "        trans_feats += [num_feat_transf.reshape((len(df),))]\n",
    "        \n",
    "        num_feat_other = df.iloc[:, i].values\n",
    "        num_feat_other_transf = np.multiply(num_feat, (1-sens_feat))\n",
    "        other_feats += [num_feat_other_transf.reshape((len(df),))]\n",
    "\n",
    "\n",
    "    temp_data = np.hstack((other_feats[0].reshape((len(df),1)), other_feats[1].reshape((len(df),1)), other_feats[2].reshape((len(df),1)),\n",
    "                           trans_feats[0].reshape((len(df),1)), trans_feats[1].reshape((len(df),1)), trans_feats[2].reshape((len(df),1)),\n",
    "                           outcome.reshape((len(df),1)), outcome_flipped.reshape((len(df),1))))\n",
    "\n",
    "    df_transf = pd.DataFrame(temp_data)\n",
    "    df_transf.columns = ['num1*(1-a)','num2*(1-a)','num3*(1-a)', 'num1*a','num2*a','num3*a','outcome', 'outcome_flipped']\n",
    "\n",
    "    # for fairness measures later\n",
    "    df_sens = df['cat']\n",
    "    maj_list = list(df[df['cat'] == 1].index)\n",
    "    min_list = list(df[df['cat'] == 0].index)\n",
    "    \n",
    "    for i in range(len(maj_list)):\n",
    "        if is_train: maj_list[i] = maj_list[i]\n",
    "        else: maj_list[i] = maj_list[i] - len(df)\n",
    "        \n",
    "    for i in range(len(min_list)):\n",
    "        if is_train:\n",
    "            min_list[i] = min_list[i]\n",
    "        else: min_list[i] = min_list[i] - len(df)\n",
    "\n",
    "    # format data\n",
    "    X_bias = df_transf.iloc[:, :-2].values\n",
    "    y_bias = df_transf.iloc[:, -1].values\n",
    "    \n",
    "    if not is_test:\n",
    "        return X_bias, y_bias, df_sens\n",
    "    else:\n",
    "        return df_transf, maj_list, min_list\n",
    "\n",
    "df_transf, _, _ = transform(df_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ea20d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ee4d59-b589-430e-b3e4-3dd928074d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def under(df, beta):\n",
    "    X_min = df.iloc[:, :].values\n",
    "    \n",
    "    # keep each example with probability beta\n",
    "    num_dropped = 0\n",
    "    for i in range(len(X_min)):\n",
    "        if random.uniform(0,1) > beta:\n",
    "            X_min = np.delete(X_min, 0, axis=0)\n",
    "            num_dropped += 1\n",
    "    print(\"Total Deleted: \", num_dropped, \"\\t % Deleted: \", num_dropped / len(df))\n",
    "    is_empty = (num_dropped / len(df)) == 1.0\n",
    "    df = pd.DataFrame(pd.DataFrame(X_min))\n",
    "    df.columns = ['num1','num2','num3','cat','outcome', 'outcome_flipped']\n",
    "    \n",
    "    return df, is_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3740995-5754-45de-9753-5f5dd9683f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(x):\n",
    "    x = np.array(x)\n",
    "    means = np.mean(x, axis = 0)\n",
    "    for i in range(len(means)):\n",
    "        if np.isnan(means[i]):\n",
    "            print('nah')\n",
    "            col_len = len(x[:, i])\n",
    "            col_sum = 0\n",
    "            for val in x[:, i]:\n",
    "                if np.isnan(val): col_len -= 1\n",
    "                else: col_sum += val\n",
    "            means[i] = col_sum / col_len\n",
    "    return means\n",
    "\n",
    "def remove_nan_std(x):\n",
    "    x = np.array(x)\n",
    "    std_devs = np.std(x, axis = 0)\n",
    "    for i in range(len(std_devs)):\n",
    "        if np.isnan(std_devs[i]):\n",
    "            print('wut')\n",
    "            col_std = []\n",
    "            for val in x[:, i]:\n",
    "                if ~np.isnan(val): col_std += [val]\n",
    "            std_devs[i] = np.std(np.array(col_std))\n",
    "    return std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0daf0345-6898-447f-9101-07ab6fd06f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tradeoff_visualization_error(r, n, apply_fairness = True, verbose = False, num_iters = 10):\n",
    "    \n",
    "    empty_dict = dict()\n",
    "    empty_dict['0.9'] = 0\n",
    "    empty_dict['0.95'] = 0\n",
    "    \n",
    "    total_fidel_maj = []\n",
    "    total_fidel_min = []\n",
    "    total_fidel = []\n",
    "    \n",
    "    total_disp_bias_train = []\n",
    "    total_disp_bo_train = []\n",
    "    total_disp_mitigated_train = []\n",
    "    \n",
    "    total_disp_bias_test = []\n",
    "    total_disp_bo_test = []\n",
    "    total_disp_mitigated_test = []\n",
    "    \n",
    "    total_acc_bias_train = []\n",
    "    total_acc_bo_train = []\n",
    "    total_acc_mitigated_train = []\n",
    "    \n",
    "    total_acc_bias_test = []\n",
    "    total_acc_bo_test = []\n",
    "    total_acc_mitigated_test = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "    \n",
    "        # 1 to 0 in increments of 0.1\n",
    "        bias_amts = np.divide(list(range(10,-1,-1)),10)\n",
    "        bias_amts[-1] = 0.05\n",
    "        \n",
    "        test_maj = []\n",
    "        test_min = []\n",
    "        total = []\n",
    "        \n",
    "        disp_bias_train = []\n",
    "        disp_bo_train = []\n",
    "        disp_mitigated_train = []\n",
    "        \n",
    "        disp_bias_test = []\n",
    "        disp_bo_test = []\n",
    "        disp_mitigated_test = []\n",
    "        \n",
    "        acc_bias_train = []\n",
    "        acc_bo_train = []\n",
    "        acc_mitigated_train = []\n",
    "        \n",
    "        acc_bias_test = []\n",
    "        acc_bo_test = []\n",
    "        acc_mitigated_test = []\n",
    "        \n",
    "        count = 0\n",
    "        outcome_continuous, df_synthetic = true_label_generation(r=r, eta=eta, n=2*n, is_exploration=False)\n",
    "        \n",
    "        threshold = 0.5\n",
    "        exact_bo_labels = np.where(outcome_continuous < threshold, 0, 1)\n",
    "        exact_bo_labels_train = np.array(exact_bo_labels[range(0,n)])\n",
    "        exact_bo_labels_test = np.array(exact_bo_labels[range(n,len(df_synthetic))])\n",
    "        \n",
    "        # split into train and test\n",
    "        df_train = df_synthetic.loc[range(0,n), :]\n",
    "        #check_groups(df_train)\n",
    "        \n",
    "        df_train_transf, maj_list, min_list = transform(df_train, True, True)\n",
    "        \n",
    "        df_test = df_synthetic.loc[range(n, len(df_synthetic)),:]\n",
    "        df_maj = df_test[df_test['cat'] == 1]\n",
    "        df_min = df_test[df_test['cat'] == 0]\n",
    "        #check_groups(df_test)\n",
    "        df_test_transf, maj_list, min_list = transform(df_test, True, False)\n",
    "        \n",
    "        df_test_maj = df_test_transf.loc[maj_list]\n",
    "        df_test_min = df_test_transf.loc[min_list]\n",
    "\n",
    "        # format training data\n",
    "        X_true = df_train_transf.iloc[:, :-2].values\n",
    "        y_true = df_train_transf.iloc[:, -1].values\n",
    "        \n",
    "        # format test data\n",
    "        X_test = df_test_transf.iloc[:, :-2].values\n",
    "        X_test_maj = df_test_maj.iloc[:, :-2].values\n",
    "        X_test_min = df_test_min.iloc[:, :-2].values\n",
    "        y_test = df_test_transf.iloc[:, -1].values\n",
    "        y_test_maj = df_test_maj.iloc[:, -1].values\n",
    "        y_test_min = df_test_min.iloc[:, -1].values\n",
    "        \n",
    "        sens_attr_test = df_test['cat']\n",
    "        sens_attr_maj = df_maj['cat']\n",
    "        sens_attr_min = df_min['cat']\n",
    "        \n",
    "        for beta in bias_amts:\n",
    "            \n",
    "            if i == 0: print(\"Beta: \", beta, '\\n')\n",
    "\n",
    "            df_train_copy = df_train.copy()\n",
    "\n",
    "            df_majority = df_train_copy[df_train_copy['cat'] == 1]\n",
    "            df_minority = df_train_copy[df_train_copy['cat'] == 0]\n",
    "            \n",
    "            # NOTE: we can use outcome_flipped in both lines below but\n",
    "            #.      we set outcome = outcome_flipped in flip_labels\n",
    "\n",
    "            # unfavored group with negative label\n",
    "            df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "            # unfavored group with positive label (preferred)\n",
    "            df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "\n",
    "            # data frame without positively labeled examples from minority class\n",
    "            df_total = pd.concat([df_majority, df_minority_negative])\n",
    "\n",
    "            # under-sampling process\n",
    "            df_undersampled, is_empty = under(df_minority_positive, beta)\n",
    "            \n",
    "            if is_empty:\n",
    "                empty_dict[str(1-beta)] += 1\n",
    "                print(empty_dict)\n",
    "\n",
    "            # combine undersampled and original favored class to create dataset\n",
    "            df_concat = pd.concat([df_total,df_undersampled]).sample(frac=1, random_state = 42)\n",
    "            #check_groups(df_concat)\n",
    "            \n",
    "            # format data\n",
    "            X_bias_true, y_bias_true, df_sens = transform(df_concat)\n",
    "            \n",
    "            # model trained on biased data\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_bias = classifier.fit(X_bias_true, y_bias_true)\n",
    "            \n",
    "            acc = accuracy_score(y_test,classifier_bias.predict(X_test))\n",
    "            #print(f'Biased classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc_bias_test += [acc]\n",
    "            acc_bias_train += [accuracy_score(y_bias_true, classifier_bias.predict(X_bias_true))]\n",
    "            \n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_test += [disparity.gamma(classify).max()]\n",
    "            \n",
    "            # Learned bayes optimal classifier\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_b = classifier.fit(X_true, y_true)        \n",
    "            #print('COEF: ', classifier_b.coef_)\n",
    "            #print('INTERCEPT: ', classifier_b.intercept_)\n",
    "            #classifier_b = clone(classifier).fit(X_true, y_true)\n",
    "            acc = accuracy_score(y_test,classifier_b.predict(X_test))\n",
    "            #print(f'Learned BO classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc_bo_test += [acc]\n",
    "            acc_bo_train += [accuracy_score(y_bias_true, classifier_b.predict(X_bias_true))]\n",
    "            \n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_test += [disparity.gamma(classify).max()]\n",
    "            \n",
    "            \n",
    "            # Exact BO optimal classifier\n",
    "            #print(f'Exact BO classifier:')\n",
    "            acc = accuracy_score(y_test,exact_bo_labels_test)\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc = accuracy_score(y_true,exact_bo_labels_train)\n",
    "            #print(f'     Train accuracy = {acc}')\n",
    "\n",
    "            if apply_fairness:\n",
    "                if not is_empty:\n",
    "                    constraint = EqualizedOdds()\n",
    "                    classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none', fit_intercept = False, max_iter = 200)   \n",
    "\n",
    "    #                 classifier_mitigated_bias = GridSearch(estimator=classifier,\n",
    "    #                                                        constraints=constraint,\n",
    "    #                                                        selection_rule='tradeoff_optimization',\n",
    "    #                                                        constraint_weight=0.5,\n",
    "    #                                                        grid_size=10,\n",
    "    #                                                        grid_limit=2.0,\n",
    "    #                                                        grid_offset=None,\n",
    "    #                                                        grid=None,\n",
    "    #                                                        sample_weight_name='sample_weight')\n",
    "\n",
    "                    classifier_mitigated_bias = ThresholdOptimizer(estimator=clone(classifier_bias), constraints= 'equalized_odds', predict_method='auto')\n",
    "\n",
    "                    classifier_mitigated_bias.fit(X_bias_true, y_bias_true, sensitive_features = df_sens)\n",
    "\n",
    "                    #acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\n",
    "                    acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test, sensitive_features=sens_attr_test))\n",
    "                    #print(f'Mitigated bias classifier:')\n",
    "                    #print(f'     Test accuracy = {acc}')\n",
    "                    acc_mitigated_test += [acc]\n",
    "                    #acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true))]\n",
    "                    acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true, sensitive_features=df_sens))]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = df_sens)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = sens_attr_test)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_test += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    # Alternative fidelity of intervention model to no intervention model\n",
    "                    alt_fid_train = accuracy_score(classifier_mitigated_bias.predict(X_bias_true, sensitive_features = df_sens),classifier_bias.predict(X_bias_true))\n",
    "                    alt_fid_test = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_bias.predict(X_test))\n",
    "                    #print(f'Alternative fidelity of intervention model to no intervention model: train = {alt_fid_train}, test = {alt_fid_test}')\n",
    "                else:\n",
    "                    disp_mitigated_train += [np.nan]\n",
    "                    disp_mitigated_test += [np.nan]\n",
    "\n",
    "                    acc_mitigated_train += [np.nan]\n",
    "                    acc_mitigated_test += [np.nan]\n",
    "\n",
    "            else:\n",
    "                classifier_mitigated_bias = clone(classifier_bias)\n",
    "                classifier_mitigated_bias.fit(X_bias_true, y_bias_true)\n",
    "                \n",
    "                disp_mitigated_train += [0]\n",
    "                disp_mitigated_test += [0]\n",
    "                \n",
    "                acc_mitigated_train += [0]\n",
    "                acc_mitigated_test += [0]\n",
    "                \n",
    "                # NOTE: disparities are the same as for classifier_bias\n",
    "\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                else:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                \n",
    "            fid = accuracy_score(classifier_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "            #print(f'Test set fidelity of learned BO classifier and biased classifier: {fid}')\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj, sensitive_features = sens_attr_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min, sensitive_features = sens_attr_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test), classifier_b.predict(X_test))]\n",
    "                else:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test), classifier_b.predict(X_test))]\n",
    "            else:\n",
    "                test_maj += [np.nan]\n",
    "                test_min += [np.nan]\n",
    "                total += [np.nan]\n",
    "                \n",
    "            if verbose:\n",
    "                #print(\"Finished Iteration: \", count)\n",
    "                count +=1\n",
    "        \n",
    "        #print(f'Fidelity test maj: {test_maj}')\n",
    "        #print(f'Fidelity test min: {test_maj}')\n",
    "        \n",
    "        total_fidel_maj.append(test_maj)\n",
    "        total_fidel_min.append(test_min)\n",
    "        total_fidel.append(total)\n",
    "        \n",
    "        total_disp_bias_train.append(disp_bias_train)\n",
    "        total_disp_bo_train.append(disp_bo_train)\n",
    "        total_disp_mitigated_train.append(disp_mitigated_train)\n",
    "\n",
    "        total_disp_bias_test.append(disp_bias_test)\n",
    "        total_disp_bo_test.append(disp_bo_test)\n",
    "        total_disp_mitigated_test.append(disp_mitigated_test)\n",
    "        \n",
    "        total_acc_bias_train.append(acc_bias_train)\n",
    "        total_acc_bo_train.append(acc_bo_train)\n",
    "        total_acc_mitigated_train.append(acc_mitigated_train)\n",
    "\n",
    "        total_acc_bias_test.append(acc_bias_test)\n",
    "        total_acc_bo_test.append(acc_bo_test)\n",
    "        total_acc_mitigated_test.append(acc_mitigated_test)\n",
    "        \n",
    "        if verbose:\n",
    "                print(\"Finished Total Iteration: \", i+1)\n",
    "                \n",
    "    if apply_fairness:\n",
    "    \n",
    "        mean_fidel_maj = remove_nan(total_fidel_maj)\n",
    "        mean_fidel_min = remove_nan(total_fidel_min)\n",
    "        mean_fidel = remove_nan(total_fidel)\n",
    "\n",
    "        mean_disp_bias_train = remove_nan(total_disp_bias_train)\n",
    "        mean_disp_bo_train = remove_nan(total_disp_bo_train)\n",
    "        mean_disp_mitigated_train = remove_nan(total_disp_mitigated_train)\n",
    "\n",
    "        mean_disp_bias_test = remove_nan(total_disp_bias_test)\n",
    "        mean_disp_bo_test = remove_nan(total_disp_bo_test)\n",
    "        mean_disp_mitigated_test = remove_nan(total_disp_mitigated_test)\n",
    "\n",
    "        y_err_disp_bias_test = remove_nan_std(total_disp_bias_test)\n",
    "        y_err_disp_bo_test = remove_nan_std(total_disp_bo_test)\n",
    "        y_err_disp_mitigated_test = remove_nan_std(total_disp_mitigated_test)\n",
    "\n",
    "        mean_acc_bias_train = remove_nan(total_acc_bias_train)\n",
    "        mean_acc_bo_train = remove_nan(total_acc_bo_train)\n",
    "        mean_acc_mitigated_train = remove_nan(total_acc_mitigated_train)\n",
    "\n",
    "        mean_acc_bias_test = remove_nan(total_acc_bias_test)\n",
    "        mean_acc_bo_test = remove_nan(total_acc_bo_test)\n",
    "        mean_acc_mitigated_test = remove_nan(total_acc_mitigated_test)\n",
    "\n",
    "        y_err_acc_bias_test = remove_nan_std(total_acc_bias_test)\n",
    "        y_err_acc_bo_test = remove_nan_std(total_acc_bo_test)\n",
    "        y_err_acc_mitigated_test = remove_nan_std(total_acc_mitigated_test)\n",
    "\n",
    "        y_err_fidel_maj = remove_nan_std(total_fidel_maj)\n",
    "        y_err_fidel_min = remove_nan_std(total_fidel_min)\n",
    "        y_err_fidel = remove_nan_std(total_fidel)\n",
    "        \n",
    "    else:\n",
    "        mean_fidel_maj = np.mean(total_fidel_maj, axis = 0)\n",
    "        mean_fidel_min = remove_nan(total_fidel_min, axis = 0)\n",
    "        mean_fidel = remove_nan(total_fidel, axis = 0)\n",
    "\n",
    "        mean_disp_bias_train = remove_nan(total_disp_bias_train, axis = 0)\n",
    "        mean_disp_bo_train = remove_nan(total_disp_bo_train, axis = 0)\n",
    "        mean_disp_mitigated_train = remove_nan(total_disp_mitigated_train, axis = 0)\n",
    "\n",
    "        mean_disp_bias_test = remove_nan(total_disp_bias_test, axis = 0)\n",
    "        mean_disp_bo_test = remove_nan(total_disp_bo_test, axis = 0)\n",
    "        mean_disp_mitigated_test = remove_nan(total_disp_mitigated_test, axis = 0)\n",
    "\n",
    "        y_err_disp_bias_test = remove_nan_std(total_disp_bias_test, axis = 0)\n",
    "        y_err_disp_bo_test = remove_nan_std(total_disp_bo_test, axis = 0)\n",
    "        y_err_disp_mitigated_test = remove_nan_std(total_disp_mitigated_test, axis = 0)\n",
    "\n",
    "        mean_acc_bias_train = remove_nan(total_acc_bias_train, axis = 0)\n",
    "        mean_acc_bo_train = remove_nan(total_acc_bo_train, axis = 0)\n",
    "        mean_acc_mitigated_train = remove_nan(total_acc_mitigated_train, axis = 0)\n",
    "\n",
    "        mean_acc_bias_test = remove_nan(total_acc_bias_test, axis = 0)\n",
    "        mean_acc_bo_test = remove_nan(total_acc_bo_test, axis = 0)\n",
    "        mean_acc_mitigated_test = remove_nan(total_acc_mitigated_test, axis = 0)\n",
    "\n",
    "        y_err_acc_bias_test = remove_nan_std(total_acc_bias_test, axis = 0)\n",
    "        y_err_acc_bo_test = remove_nan_std(total_acc_bo_test, axis = 0)\n",
    "        y_err_acc_mitigated_test = remove_nan_std(total_acc_mitigated_test, axis = 0)\n",
    "\n",
    "        y_err_fidel_maj = remove_nan_std(total_fidel_maj)\n",
    "        y_err_fidel_min = remove_nan_std(total_fidel_min)\n",
    "        y_err_fidel = remove_nan_std(total_fidel)\n",
    "        \n",
    "    \n",
    "    \n",
    "    df_disp = pd.DataFrame({\"Biased Train\" : mean_disp_bias_train,\n",
    "                       \"BO Train\" : mean_disp_bo_train,\n",
    "                       \"Mitigated Train\" : mean_disp_mitigated_train,\n",
    "                       \"Biased Test\" : mean_disp_bias_test,\n",
    "                       \"BO Test\" : mean_disp_bo_test,\n",
    "                       \"Mitigated Test\" : mean_disp_mitigated_test,\n",
    "                       \"Err Biased Test\": y_err_disp_bias_test,\n",
    "                       \"Err BO Test\": y_err_disp_bo_test,\n",
    "                       \"Err Mitigated Test\": y_err_disp_mitigated_test})\n",
    "    \n",
    "    df_acc = pd.DataFrame({\"Biased Train\" : mean_acc_bias_train,\n",
    "                       \"BO Train\" : mean_acc_bo_train,\n",
    "                       \"Mitigated Train\" : mean_acc_mitigated_train,\n",
    "                       \"Biased Test\" : mean_acc_bias_test,\n",
    "                       \"BO Test\" : mean_acc_bo_test,\n",
    "                       \"Mitigated Test\" : mean_acc_mitigated_test,\n",
    "                       \"Err Biased Test\": y_err_acc_bias_test,\n",
    "                       \"Err BO Test\": y_err_acc_bo_test,\n",
    "                       \"Err Mitigated Test\": y_err_acc_mitigated_test})\n",
    "   \n",
    "    return bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5baa9-4d72-4f82-b02f-4104567d698f",
   "metadata": {},
   "source": [
    "### Section 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ccbcfad-6294-4d9b-bc3c-53ae73eeea1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=300\n",
      "Run simulation with intervention...\n",
      "Diff:  -0.06250000000000006\n",
      "Beta:  1.0 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Beta:  0.9 \n",
      "\n",
      "Total Deleted:  3 \t % Deleted:  0.09090909090909091\n",
      "Beta:  0.8 \n",
      "\n",
      "Total Deleted:  5 \t % Deleted:  0.15151515151515152\n",
      "Beta:  0.7 \n",
      "\n",
      "Total Deleted:  9 \t % Deleted:  0.2727272727272727\n",
      "Beta:  0.6 \n",
      "\n",
      "Total Deleted:  13 \t % Deleted:  0.3939393939393939\n",
      "Beta:  0.5 \n",
      "\n",
      "Total Deleted:  20 \t % Deleted:  0.6060606060606061\n",
      "Beta:  0.4 \n",
      "\n",
      "Total Deleted:  23 \t % Deleted:  0.696969696969697\n",
      "Beta:  0.3 \n",
      "\n",
      "Total Deleted:  29 \t % Deleted:  0.8787878787878788\n",
      "Beta:  0.2 \n",
      "\n",
      "Total Deleted:  25 \t % Deleted:  0.7575757575757576\n",
      "Beta:  0.1 \n",
      "\n",
      "Total Deleted:  31 \t % Deleted:  0.9393939393939394\n",
      "Beta:  0.05 \n",
      "\n",
      "Total Deleted:  32 \t % Deleted:  0.9696969696969697\n",
      "nah\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a1b2242ff158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mapply_fairness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_disp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtradeoff_visualization_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_fairness\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdf_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias_amts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel_maj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel_min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel_maj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel_min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdf_disp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'disp_with_intervention_numiters{num_iters}_n{n}_eta{eta}_fairness{apply_fairness}.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-34b9a114ee65>\u001b[0m in \u001b[0;36mtradeoff_visualization_error\u001b[0;34m(r, n, apply_fairness, verbose, num_iters)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mmean_fidel_maj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_fidel_maj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0mmean_fidel_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_fidel_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mmean_fidel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_fidel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f82a0df1f8da>\u001b[0m in \u001b[0;36mremove_nan\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcol_len\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcol_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_sum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcol_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#Run experiments for section 4 and save data\n",
    "import warnings\n",
    "import time\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "for n in [300,3000,30000]:\n",
    "#for n in [300]:\n",
    "\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    eta = 0.4\n",
    "    r = 0.2\n",
    "    num_iters = 1\n",
    "    \n",
    "    print(f'n={n}')\n",
    "    \n",
    "    print(f'Run simulation with intervention...')\n",
    "    start_time = time.time()\n",
    "    apply_fairness = True\n",
    "    bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc = \\\n",
    "    tradeoff_visualization_error(r=r, n=n, apply_fairness=apply_fairness,verbose=False, num_iters=num_iters)\n",
    "    df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T, columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "    df_disp.to_csv(f'disp_with_intervention_numiters{num_iters}_n{n}_eta{eta}_fairness{apply_fairness}.csv', index = True)\n",
    "    df_res.to_csv(f'fid_with_intervention_numiters{num_iters}_n{n}_eta{eta}_fairness{apply_fairness}.csv', index = True)\n",
    "    df_acc.to_csv(f'acc_with_intervention_numiters{num_iters}_n{n}_eta{eta}_fairness{apply_fairness}.csv', index = True)\n",
    "    print(f'Took {(time.time() - start_time)/60} minutes.')\n",
    "    \n",
    "    print(f'Run simulation without intervention...')\n",
    "    start_time = time.time()\n",
    "    apply_fairness = False\n",
    "    bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc = \\\n",
    "    tradeoff_visualization_error(r = r, n = n, apply_fairness=apply_fairness,verbose=False, num_iters=num_iters)\n",
    "    df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T, columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "    df_disp.to_csv(f'disp_without_intervention_numiters{num_iters}_n{n}_eta{eta}_fairness{apply_fairness}.csv', index = True)\n",
    "    df_res.to_csv(f'fid_without_intervention_numiters{num_iters}_n{n}_eta{eta}_fairness{apply_fairness}.csv', index = True)\n",
    "    df_acc.to_csv(f'acc_without_intervention_numiters{num_iters}_n{n}_eta{eta}_fairness{apply_fairness}.csv', index = True)\n",
    "    print(f'Took {(time.time() - start_time)/60} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "708d011d-2931-43aa-acee-0af5a8fc555c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make plots for section 4\n",
    "\n",
    "for n in [300,3000,30000]:\n",
    "\n",
    "    eta = 0.4\n",
    "    num_iters = 50\n",
    "\n",
    "    df_fair = pd.read_csv(f'fid_with_intervention_numiters{num_iters}_n{n}_eta{eta}_fairnessTrue.csv')\n",
    "    df_bias = pd.read_csv(f'fid_without_intervention_numiters{num_iters}_n{n}_eta{eta}_fairnessFalse.csv')\n",
    "\n",
    "    a = 0.5\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    markers, caps, bars = ax.errorbar(1-df_fair.bias_amts, df_fair.mean_fidel_maj, yerr = df_fair.y_err_fidel_maj, \n",
    "                                      label = 'With intervention majority group', color = \"orange\",\n",
    "                                      capsize=4, capthick=2)\n",
    "    [bar.set_alpha(a) for bar in bars]\n",
    "    [cap.set_alpha(a) for cap in caps]\n",
    "    markers, caps, bars = ax.errorbar(1-df_fair.bias_amts, df_fair.mean_fidel_min, yerr = df_fair.y_err_fidel_min, \n",
    "                                      label = 'With intervention minority group', color = \"orange\",\n",
    "                                      capsize=4, capthick=2, linestyle='--')\n",
    "    [bar.set_linestyle('--') for bar in bars]\n",
    "    [bar.set_alpha(a) for bar in bars]\n",
    "    [cap.set_alpha(a) for cap in caps]\n",
    "    markers, caps, bars = ax.errorbar(1-df_bias.bias_amts, df_bias.mean_fidel_maj, yerr = df_bias.y_err_fidel_maj, \n",
    "                                      label = 'Without intervention majority group', color = \"blue\",\n",
    "                                      capsize=4, capthick=2)\n",
    "    [bar.set_alpha(a) for bar in bars]\n",
    "    [cap.set_alpha(a) for cap in caps]\n",
    "    markers, caps, bars = ax.errorbar(1-df_bias.bias_amts, df_bias.mean_fidel_min, yerr = df_bias.y_err_fidel_min, \n",
    "                                      label = 'Without intervention minority group', color = \"blue\",\n",
    "                                      capsize=4, capthick=2, linestyle='--')\n",
    "    [bar.set_linestyle('--') for bar in bars]\n",
    "    [bar.set_alpha(a) for bar in bars]\n",
    "    [cap.set_alpha(a) for cap in caps]\n",
    "    \n",
    "    #plt.errorbar(df_fair.bias_amts, df_fair.mean_fidel_maj, yerr = df_fair.y_err_fidel_maj, label = 'With intervention majority group', color = \"orange\")\n",
    "    #plt.errorbar(df_fair.bias_amts, df_fair.mean_fidel_min, yerr = df_fair.y_err_fidel_min, label = 'With intervention minority group', color = \"orange\", linestyle = '--')\n",
    "    #plt.errorbar(df_bias.bias_amts, df_bias.mean_fidel_maj, yerr = df_bias.y_err_fidel_maj, label = 'Without intervention majority group', color = \"blue\")\n",
    "    #plt.errorbar(df_bias.bias_amts, df_bias.mean_fidel_min, yerr = df_bias.y_err_fidel_min, label = 'Without intervention minority group', color = \"blue\", linestyle = '--')\n",
    "    #plt.errorbar(bias_amts, mean_fidel, yerr = y_err_fidel, label = 'Total Fidelity', color = \"blue\")\n",
    "    \n",
    "    plt.xlabel(r\"Amount of injected underrep. bias $1-\\beta$\")\n",
    "    plt.ylabel(f\"Fidelity with n={n}\")\n",
    "    #plt.xlim(1.05, -0.05)\n",
    "    plt.ylim(0.35, 1.05)\n",
    "    if n == 30000:\n",
    "        plt.legend()\n",
    "    plt.savefig(f'section4_n{n}.jpg',dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a719050b-374d-457a-91bb-ef2df12f8774",
   "metadata": {},
   "source": [
    "# Exploration (Section 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a842d-544e-4b41-992a-022c43cf3d2d",
   "metadata": {},
   "source": [
    "## Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25440d5e-3a5b-431f-b4d0-078ff50ec04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation(r, n, apply_fairness = True, verbose = False, num_iters = 10, inter = False, diff_base = False):\n",
    "    \n",
    "    empty_dict = dict()\n",
    "    empty_dict['0.9'] = 0\n",
    "    empty_dict['0.95'] = 0\n",
    "    \n",
    "    total_fidel_maj = []\n",
    "    total_fidel_min = []\n",
    "    total_fidel = []\n",
    "    \n",
    "    total_disp_bias_train = []\n",
    "    total_disp_bo_train = []\n",
    "    total_disp_mitigated_train = []\n",
    "    \n",
    "    total_disp_bias_test = []\n",
    "    total_disp_bo_test = []\n",
    "    total_disp_mitigated_test = []\n",
    "    \n",
    "    total_acc_bias_train = []\n",
    "    total_acc_bo_train = []\n",
    "    total_acc_mitigated_train = []\n",
    "    \n",
    "    total_acc_bias_test = []\n",
    "    total_acc_bo_test = []\n",
    "    total_acc_mitigated_test = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "    \n",
    "        # 1 to 0 in increments of 0.1\n",
    "        bias_amts = np.divide(list(range(10,-1,-1)),10)\n",
    "        bias_amts[-1] = 0.05\n",
    "        \n",
    "        test_maj = []\n",
    "        test_min = []\n",
    "        total = []\n",
    "        \n",
    "        disp_bias_train = []\n",
    "        disp_bo_train = []\n",
    "        disp_mitigated_train = []\n",
    "        \n",
    "        disp_bias_test = []\n",
    "        disp_bo_test = []\n",
    "        disp_mitigated_test = []\n",
    "        \n",
    "        acc_bias_train = []\n",
    "        acc_bo_train = []\n",
    "        acc_mitigated_train = []\n",
    "        \n",
    "        acc_bias_test = []\n",
    "        acc_bo_test = []\n",
    "        acc_mitigated_test = []\n",
    "        \n",
    "        count = 0\n",
    "        outcome_continuous, df_synthetic = true_label_generation(r=r, eta=eta, n=2*n, is_exploration=False)\n",
    "        \n",
    "        threshold = 0.5\n",
    "        exact_bo_labels = np.where(outcome_continuous < threshold, 0, 1)\n",
    "        exact_bo_labels_train = np.array(exact_bo_labels[range(0,n)])\n",
    "        exact_bo_labels_test = np.array(exact_bo_labels[range(n,len(df_synthetic))])\n",
    "        \n",
    "        # split into train and test\n",
    "        df_train = df_synthetic.loc[range(0,n), :]\n",
    "        #check_groups(df_train)\n",
    "        \n",
    "        df_train_transf, maj_list, min_list = transform(df_train, True, True)\n",
    "        \n",
    "        df_test = df_synthetic.loc[range(n, len(df_synthetic)),:]\n",
    "        df_maj = df_test[df_test['cat'] == 1]\n",
    "        df_min = df_test[df_test['cat'] == 0]\n",
    "        #check_groups(df_test)\n",
    "        df_test_transf, maj_list, min_list = transform(df_test, True, False)\n",
    "        \n",
    "        df_test_maj = df_test_transf.loc[maj_list]\n",
    "        df_test_min = df_test_transf.loc[min_list]\n",
    "\n",
    "        # format training data\n",
    "        X_true = df_train_transf.iloc[:, :-2].values\n",
    "        y_true = df_train_transf.iloc[:, -1].values\n",
    "        \n",
    "        # format test data\n",
    "        X_test = df_test_transf.iloc[:, :-2].values\n",
    "        X_test_maj = df_test_maj.iloc[:, :-2].values\n",
    "        X_test_min = df_test_min.iloc[:, :-2].values\n",
    "        y_test = df_test_transf.iloc[:, -1].values\n",
    "        y_test_maj = df_test_maj.iloc[:, -1].values\n",
    "        y_test_min = df_test_min.iloc[:, -1].values\n",
    "        \n",
    "        sens_attr_test = df_test['cat']\n",
    "        sens_attr_maj = df_maj['cat']\n",
    "        sens_attr_min = df_min['cat']\n",
    "        \n",
    "        for beta in bias_amts:\n",
    "            \n",
    "            if i == 0: print(\"Beta: \", beta, '\\n')\n",
    "\n",
    "            df_train_copy = df_train.copy()\n",
    "\n",
    "            df_majority = df_train_copy[df_train_copy['cat'] == 1]\n",
    "            df_minority = df_train_copy[df_train_copy['cat'] == 0]\n",
    "\n",
    "            if inter:\n",
    "                # unfavored group with negative label\n",
    "                df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "                # unfavored group with positive label (preferred)\n",
    "                df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "\n",
    "                # data frame without positively labeled examples from minority class\n",
    "                df_total = pd.concat([df_majority, df_minority_negative])\n",
    "\n",
    "                df_undersampled, is_empty = under(df_minority_positive, beta)\n",
    "\n",
    "                # combine undersampled and original favored class to create dataset\n",
    "                df_concat = pd.concat([df_total,df_undersampled]).sample(frac=1, random_state = 42) # permute data\n",
    "\n",
    "            else:\n",
    "                df_undersampled, is_empty = under(df_minority, beta)\n",
    "\n",
    "                # combine undersampled and original favored class to create dataset\n",
    "                df_concat = pd.concat([df_majority,df_undersampled])\n",
    "                df_concat.sample(frac=1, random_state = 42) # permute data\n",
    "\n",
    "            if is_empty:\n",
    "                empty_dict[str(1-beta)] += 1\n",
    "                print(empty_dict)\n",
    "            \n",
    "            # format data\n",
    "            X_bias_true, y_bias_true, df_sens = transform(df_concat)\n",
    "            \n",
    "            # model trained on biased data\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_bias = classifier.fit(X_bias_true, y_bias_true)\n",
    "            \n",
    "            acc = accuracy_score(y_test,classifier_bias.predict(X_test))\n",
    "            #print(f'Biased classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc_bias_test += [acc]\n",
    "            acc_bias_train += [accuracy_score(y_bias_true, classifier_bias.predict(X_bias_true))]\n",
    "            \n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_test += [disparity.gamma(classify).max()]\n",
    "            \n",
    "            # Learned bayes optimal classifier\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_b = classifier.fit(X_true, y_true)        \n",
    "            #print('COEF: ', classifier_b.coef_)\n",
    "            #print('INTERCEPT: ', classifier_b.intercept_)\n",
    "            #classifier_b = clone(classifier).fit(X_true, y_true)\n",
    "            acc = accuracy_score(y_test,classifier_b.predict(X_test))\n",
    "            #print(f'Learned BO classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc_bo_test += [acc]\n",
    "            acc_bo_train += [accuracy_score(y_bias_true, classifier_b.predict(X_bias_true))]\n",
    "            \n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_test += [disparity.gamma(classify).max()]\n",
    "            \n",
    "            \n",
    "            # Exact BO optimal classifier\n",
    "            #print(f'Exact BO classifier:')\n",
    "            acc = accuracy_score(y_test,exact_bo_labels_test)\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc = accuracy_score(y_true,exact_bo_labels_train)\n",
    "            #print(f'     Train accuracy = {acc}')\n",
    "\n",
    "            if apply_fairness:\n",
    "                if not is_empty:\n",
    "                    constraint = EqualizedOdds()\n",
    "                    classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none', fit_intercept = False, max_iter = 200)   \n",
    "\n",
    "    #                 classifier_mitigated_bias = GridSearch(estimator=classifier,\n",
    "    #                                                        constraints=constraint,\n",
    "    #                                                        selection_rule='tradeoff_optimization',\n",
    "    #                                                        constraint_weight=0.5,\n",
    "    #                                                        grid_size=10,\n",
    "    #                                                        grid_limit=2.0,\n",
    "    #                                                        grid_offset=None,\n",
    "    #                                                        grid=None,\n",
    "    #                                                        sample_weight_name='sample_weight')\n",
    "\n",
    "                    classifier_mitigated_bias = ThresholdOptimizer(estimator=clone(classifier_bias), constraints= 'equalized_odds', predict_method='auto')\n",
    "\n",
    "                    classifier_mitigated_bias.fit(X_bias_true, y_bias_true, sensitive_features = df_sens)\n",
    "\n",
    "                    #acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\n",
    "                    acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test, sensitive_features=sens_attr_test))\n",
    "                    #print(f'Mitigated bias classifier:')\n",
    "                    #print(f'     Test accuracy = {acc}')\n",
    "                    acc_mitigated_test += [acc]\n",
    "                    #acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true))]\n",
    "                    acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true, sensitive_features=df_sens))]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = df_sens)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = sens_attr_test)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_test += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    # Alternative fidelity of intervention model to no intervention model\n",
    "                    alt_fid_train = accuracy_score(classifier_mitigated_bias.predict(X_bias_true, sensitive_features = df_sens),classifier_bias.predict(X_bias_true))\n",
    "                    alt_fid_test = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_bias.predict(X_test))\n",
    "                    #print(f'Alternative fidelity of intervention model to no intervention model: train = {alt_fid_train}, test = {alt_fid_test}')\n",
    "                else:\n",
    "                    disp_mitigated_train += [np.nan]\n",
    "                    disp_mitigated_test += [np.nan]\n",
    "\n",
    "                    acc_mitigated_train += [np.nan]\n",
    "                    acc_mitigated_test += [np.nan]\n",
    "\n",
    "            else:\n",
    "                classifier_mitigated_bias = clone(classifier_bias)\n",
    "                classifier_mitigated_bias.fit(X_bias_true, y_bias_true)\n",
    "                \n",
    "                disp_mitigated_train += [0]\n",
    "                disp_mitigated_test += [0]\n",
    "                \n",
    "                acc_mitigated_train += [0]\n",
    "                acc_mitigated_test += [0]\n",
    "                \n",
    "                # NOTE: disparities are the same as for classifier_bias\n",
    "\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                else:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                \n",
    "            fid = accuracy_score(classifier_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "            #print(f'Test set fidelity of learned BO classifier and biased classifier: {fid}')\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj, sensitive_features = sens_attr_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min, sensitive_features = sens_attr_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test), classifier_b.predict(X_test))]\n",
    "                else:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test), classifier_b.predict(X_test))]\n",
    "            else:\n",
    "                test_maj += [np.nan]\n",
    "                test_min += [np.nan]\n",
    "                total += [np.nan]\n",
    "                \n",
    "            if verbose:\n",
    "                #print(\"Finished Iteration: \", count)\n",
    "                count +=1\n",
    "        \n",
    "        #print(f'Fidelity test maj: {test_maj}')\n",
    "        #print(f'Fidelity test min: {test_maj}')\n",
    "        \n",
    "        total_fidel_maj.append(test_maj)\n",
    "        total_fidel_min.append(test_min)\n",
    "        total_fidel.append(total)\n",
    "        \n",
    "        total_disp_bias_train.append(disp_bias_train)\n",
    "        total_disp_bo_train.append(disp_bo_train)\n",
    "        total_disp_mitigated_train.append(disp_mitigated_train)\n",
    "\n",
    "        total_disp_bias_test.append(disp_bias_test)\n",
    "        total_disp_bo_test.append(disp_bo_test)\n",
    "        total_disp_mitigated_test.append(disp_mitigated_test)\n",
    "        \n",
    "        total_acc_bias_train.append(acc_bias_train)\n",
    "        total_acc_bo_train.append(acc_bo_train)\n",
    "        total_acc_mitigated_train.append(acc_mitigated_train)\n",
    "\n",
    "        total_acc_bias_test.append(acc_bias_test)\n",
    "        total_acc_bo_test.append(acc_bo_test)\n",
    "        total_acc_mitigated_test.append(acc_mitigated_test)\n",
    "        \n",
    "        if verbose:\n",
    "                print(\"Finished Total Iteration: \", i+1)\n",
    "    \n",
    "    mean_fidel_maj = remove_nan(total_fidel_maj)\n",
    "    mean_fidel_min = remove_nan(total_fidel_min)\n",
    "    mean_fidel = remove_nan(total_fidel)\n",
    "    \n",
    "    mean_disp_bias_train = remove_nan(total_disp_bias_train)\n",
    "    mean_disp_bo_train = remove_nan(total_disp_bo_train)\n",
    "    mean_disp_mitigated_train = remove_nan(total_disp_mitigated_train)\n",
    "    \n",
    "    mean_disp_bias_test = remove_nan(total_disp_bias_test)\n",
    "    mean_disp_bo_test = remove_nan(total_disp_bo_test)\n",
    "    mean_disp_mitigated_test = remove_nan(total_disp_mitigated_test)\n",
    "    \n",
    "    mean_acc_bias_train = remove_nan(total_acc_bias_train)\n",
    "    mean_acc_bo_train = remove_nan(total_acc_bo_train)\n",
    "    mean_acc_mitigated_train = remove_nan(total_acc_mitigated_train)\n",
    "    \n",
    "    mean_acc_bias_test = remove_nan(total_acc_bias_test)\n",
    "    mean_acc_bo_test = remove_nan(total_acc_bo_test)\n",
    "    mean_acc_mitigated_test = remove_nan(total_acc_mitigated_test)\n",
    "    \n",
    "    y_err_fidel_maj = remove_nan_std(total_fidel_maj)\n",
    "    y_err_fidel_min = remove_nan_std(total_fidel_min)\n",
    "    y_err_fidel = remove_nan_std(total_fidel)\n",
    "    \n",
    "    \n",
    "    df_disp = pd.DataFrame({\"Biased Train\" : mean_disp_bias_train,\n",
    "                       \"BO Train\" : mean_disp_bo_train,\n",
    "                       \"Mitigated Train\" : mean_disp_mitigated_train,\n",
    "                       \"Biased Test\" : mean_disp_bias_test,\n",
    "                       \"BO Test\" : mean_disp_bo_test,\n",
    "                       \"Mitigated Test\" : mean_disp_mitigated_test})\n",
    "    \n",
    "    df_acc = pd.DataFrame({\"Biased Train\" : mean_acc_bias_train,\n",
    "                       \"BO Train\" : mean_acc_bo_train,\n",
    "                       \"Mitigated Train\" : mean_acc_mitigated_train,\n",
    "                       \"Biased Test\" : mean_acc_bias_test,\n",
    "                       \"BO Test\" : mean_acc_bo_test,\n",
    "                       \"Mitigated Test\" : mean_acc_mitigated_test})\n",
    "   \n",
    "    return bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60507e31-79c5-4ee7-a6e7-0143ed7b4f10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  0.008458333333333345\n",
      "Beta:  1.0 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Beta:  0.9 \n",
      "\n",
      "Total Deleted:  601 \t % Deleted:  0.10145172180958811\n",
      "Beta:  0.8 \n",
      "\n",
      "Total Deleted:  1236 \t % Deleted:  0.2086428089128967\n",
      "Beta:  0.7 \n",
      "\n",
      "Total Deleted:  1809 \t % Deleted:  0.30536799459824443\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-851f257b0146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_disp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T,\n",
      "\u001b[0;32m<ipython-input-16-1e137d3f8fdf>\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;31m#print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0;31m#print(f'Test set fidelity of learned BO classifier and biased classifier: {fid}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 721\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[0;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2242\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc = \\\n",
    "representation(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = False, inter = False)\n",
    "\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T,\n",
    "                      columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_disp.to_csv(f'disp_repr_no_inter.csv', index = True)\n",
    "df_res.to_csv(f'fid_repr_no_inter.csv', index = True)\n",
    "df_acc.to_csv(f'acc_repr_no_inter.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9c94ae-52f6-4015-9971-46ed43d8c1df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  0.008458333333333345\n",
      "Beta:  1.0 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Beta:  0.9 \n",
      "\n",
      "Total Deleted:  298 \t % Deleted:  0.10215975317106617\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9564d9eebbb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_disp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T,\n",
      "\u001b[0;32m<ipython-input-16-1e137d3f8fdf>\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;31m# Learned bayes optimal classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mclassifier_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;31m#print('COEF: ', classifier_b.coef_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m#print('INTERCEPT: ', classifier_b.intercept_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1414\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1416\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             )\n\u001b[1;32m    763\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_intercept_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_intercept_dot\u001b[0;34m(w, X, y)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc = \\\n",
    "representation(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = False, inter = True)\n",
    "\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T,\n",
    "                      columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_disp.to_csv(f'disp_repr_inter.csv', index = True)\n",
    "df_res.to_csv(f'fid_repr_inter.csv', index = True)\n",
    "df_acc.to_csv(f'acc_repr_inter.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f8590be-6740-467c-8a4c-2232d7918caa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  0.008458333333333345\n",
      "Beta:  1.0 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Beta:  0.9 \n",
      "\n",
      "Total Deleted:  298 \t % Deleted:  0.10215975317106617\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dfe515e26c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_disp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T,\n",
      "\u001b[0;32m<ipython-input-16-1e137d3f8fdf>\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mclassifier_mitigated_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThresholdOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'equalized_odds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                     \u001b[0mclassifier_mitigated_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     \u001b[0;31m#acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sensitive_features, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         self.interpolated_thresholder_ = threshold_optimization_method(\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0msensitive_feature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36m_threshold_optimization_for_equalized_odds\u001b[0;34m(self, sensitive_features, labels, scores)\u001b[0m\n\u001b[1;32m    535\u001b[0m         ) in data_grouped_by_sensitive_feature:\n\u001b[1;32m    536\u001b[0m             roc_convex_hull = _tradeoff_curve(\n\u001b[0;32m--> 537\u001b[0;31m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_feature_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m             )\n\u001b[1;32m    539\u001b[0m             self._tradeoff_curve[sensitive_feature_value] = _interpolate_curve(\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_tradeoff_curve\u001b[0;34m(data, sensitive_feature_value, flip, x_metric, y_metric)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m     95\u001b[0m     points_sorted = _calculate_tradeoff_points(\n\u001b[0;32m---> 96\u001b[0;31m         data, sensitive_feature_value, flip=flip, x_metric=x_metric, y_metric=y_metric)\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mpoints_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_points_to_get_convex_hull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mconvex_hull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'operation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_calculate_tradeoff_points\u001b[0;34m(data, sensitive_feature_value, flip, x_metric, y_metric)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mtrue_positives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mtrue_negatives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_negative\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             false_negatives=(n_positive - count[1]))\n\u001b[0m\u001b[1;32m    253\u001b[0m         flipped_counts = _extend_confusion_matrix(\n\u001b[1;32m    254\u001b[0m             \u001b[0mfalse_positives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_negative\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_extend_confusion_matrix\u001b[0;34m(true_positives, false_positives, true_negatives, false_negatives)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mpositives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mnegatives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_negatives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrue_negatives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc = \\\n",
    "representation(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = True, inter = True)\n",
    "\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T,\n",
    "                      columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_disp.to_csv(f'disp_repr_diff_base.csv', index = True)\n",
    "df_res.to_csv(f'fid_repr_diff_base.csv', index = True)\n",
    "df_acc.to_csv(f'acc_repr_diff_base.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83012064-1e3e-47c5-83b9-e49c38db2e90",
   "metadata": {},
   "source": [
    "## Label Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83663e42-1cb4-4ecb-991e-bd4d83ed3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(df, eta):\n",
    "    labels = copy.deepcopy(list(df['outcome'].values))\n",
    "    #print('Before:', df['outcome_flipped'].value_counts())\n",
    "    num_flipped = 0\n",
    "    for i in range(len(labels)):\n",
    "        if random.uniform(0,1) <= eta:\n",
    "            labels[i] = 1 if labels[i] == 0 else 0\n",
    "            num_flipped += 1\n",
    "    df['outcome_flipped'] = labels\n",
    "    #print('After:', df['outcome_flipped'].value_counts())\n",
    "    print('Pos Min Flipped: ', num_flipped, \"\\tRate: \", num_flipped / len(df))\n",
    "    return df\n",
    "\n",
    "def get_noise(df, beta, inter = False, is_init = True):\n",
    "    df_majority = df[df['cat'] == 1]\n",
    "    df_minority = df[df['cat'] == 0]\n",
    "    \n",
    "    if inter:\n",
    "        # unfavored group with negative label\n",
    "        df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "        # unfavored group with positive label (preferred)\n",
    "        df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "        \n",
    "        if is_init:\n",
    "            \n",
    "            df_undersampled_majog = flip(df_majority, 0.4)\n",
    "        \n",
    "            df_undersampled_maj = flip(df_minority_negative, 0.4)\n",
    "\n",
    "            df_undersampled = flip(df_minority_positive, beta)\n",
    "\n",
    "            df_concat = pd.concat([df_undersampled_majog,df_undersampled_maj,df_undersampled])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            df_total = pd.concat([df_majority, df_minority_negative])\n",
    "            \n",
    "            df_undersampled = flip(df_minority_positive, beta)\n",
    "            \n",
    "            df_concat = pd.concat([df_total,df_undersampled])\n",
    "        \n",
    "\n",
    "        return df_concat.sample(frac=1, random_state = 42) # permute data\n",
    "    \n",
    "    else:\n",
    "        df_undersampled = flip(df_minority, beta)\n",
    "\n",
    "        # combine undersampled and original favored class to create dataset\n",
    "        df_concat = pd.concat([df_majority,df_undersampled])\n",
    "\n",
    "        return df_concat.sample(frac=1, random_state = 42) # permute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a92a2670-6214-46a0-8845-1a19baeeee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_noise(r, n, apply_fairness = True, verbose = False, num_iters = 10, inter = False, diff_base = False):\n",
    "    \n",
    "    total_fidel_maj = []\n",
    "    total_fidel_min = []\n",
    "    total_fidel = []\n",
    "    \n",
    "    total_disp_bias_train = []\n",
    "    total_disp_bo_train = []\n",
    "    total_disp_mitigated_train = []\n",
    "    \n",
    "    total_disp_bias_test = []\n",
    "    total_disp_bo_test = []\n",
    "    total_disp_mitigated_test = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "    \n",
    "        # 1 to 0 in increments of 0.1\n",
    "        bias_amts = np.divide(list(range(0,10,1)),20)\n",
    "\n",
    "        test_maj = []\n",
    "        test_min = []\n",
    "        total = []\n",
    "        \n",
    "        disp_bias_train = []\n",
    "        disp_bo_train = []\n",
    "        disp_mitigated_train = []\n",
    "        \n",
    "        disp_bias_test = []\n",
    "        disp_bo_test = []\n",
    "        disp_mitigated_test = []\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        if diff_base: \n",
    "            #outcome_continuous, df_synthetic = true_label_generation(r=r, eta=eta, n=2*n, maj_means =[0.7,0.7,0.7], is_exploration = True)\n",
    "            _, df_train = true_label_generation(r=r, eta=eta, n=n, maj_means =[0.7,0.7,0.7], is_exploration = True)\n",
    "            _, df_test = true_label_generation(r=r, eta=eta, n=n, maj_means =[0.7,0.7,0.7], is_exploration = False)\n",
    "        else: \n",
    "            print('generating train')\n",
    "            _, df_train = true_label_generation(r=r, eta=eta, n=n, is_exploration = True, inter = inter)\n",
    "            print('\\ngenerating test')\n",
    "            _, df_test = true_label_generation(r=r, eta=eta, n=n, is_exploration = False, inter = True) \n",
    "            #_, df_synthetic = true_label_generation(r=r, eta=eta, n=2*n, is_exploration = False) \n",
    "            \n",
    "        threshold = 0.5\n",
    "        exact_bo_labels = np.where(outcome_continuous < threshold, 0, 1)\n",
    "        exact_bo_labels_train = np.array(exact_bo_labels[range(0,n)])\n",
    "        exact_bo_labels_test = np.array(exact_bo_labels[range(n,len(df_synthetic))])\n",
    "        \n",
    "        # split into train and test\n",
    "        #df_train = df_synthetic.loc[range(0,n), :]\n",
    "        \n",
    "        #df_train = get_noise(df_train, 0, inter = True)\n",
    "        #print(\"true train\")\n",
    "        #check_groups(df_train)\n",
    "        \n",
    "        df_train_bo = get_noise(df_train.copy(), 0.4, inter = inter, is_init = False)\n",
    "        #print(\"true train with pos min noise\")\n",
    "        #check_groups(df_train_bo)\n",
    "        \n",
    "        X_true, y_true, df_sens_true = transform(df_train_bo, False, True)\n",
    "        is_empty = False\n",
    "        \n",
    "        # format training data\n",
    "        #X_true = df_train_transf_bo.iloc[:, :-2].values\n",
    "        #y_true = df_train_transf_bo.iloc[:, -1].values\n",
    "        \n",
    "        #df_test = df_synthetic.loc[range(n, len(df_synthetic)),:]\n",
    "        #print(\"test\")\n",
    "        #check_groups(df_test)\n",
    "        \n",
    "        #df_train_transf, maj_list, min_list = transform(df_train, True, True)\n",
    "        \n",
    "        #df_test = get_noise(df_test, 0, inter = True)\n",
    "        df_maj = df_test[df_test['cat'] == 1]\n",
    "        df_min = df_test[df_test['cat'] == 0]\n",
    "        \n",
    "        df_test_transf, maj_list, min_list = transform(df_test, True, True)\n",
    "        \n",
    "        df_test_maj = df_test_transf.loc[maj_list]\n",
    "        df_test_min = df_test_transf.loc[min_list]\n",
    "        \n",
    "        # format test data\n",
    "        X_test = df_test_transf.iloc[:, :-2].values\n",
    "        X_test_maj = df_test_maj.iloc[:, :-2].values\n",
    "        X_test_min = df_test_min.iloc[:, :-2].values\n",
    "        y_test = df_test_transf.iloc[:, -1].values\n",
    "        y_test_maj = df_test_maj.iloc[:, -1].values\n",
    "        y_test_min = df_test_min.iloc[:, -1].values\n",
    "        \n",
    "        sens_attr_test = df_test['cat']\n",
    "        sens_attr_maj = df_maj['cat']\n",
    "        sens_attr_min = df_min['cat']\n",
    "        \n",
    "        for beta in bias_amts: #[0.4]\n",
    "            \n",
    "            if i == 0: print(\"Beta: \", beta, '\\n')\n",
    "\n",
    "            df_train_copy = df_train.copy()\n",
    "            \n",
    "            df_concat = get_noise(df_train_copy, beta, inter, is_init = False) # group-dependent label noise\n",
    "            #print(\"biased train\")\n",
    "            #check_groups(df_concat)\n",
    "\n",
    "            # format data\n",
    "            X_bias_true, y_bias_true, df_sens = transform(df_concat)\n",
    "            \n",
    "            # model trained on biased data\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            if beta == 0.4:\n",
    "                classifier_bias = classifier.fit(X_true, y_true)\n",
    "            else:\n",
    "                classifier_bias = classifier.fit(X_bias_true, y_bias_true)\n",
    "            \n",
    "            acc = accuracy_score(y_test,classifier_bias.predict(X_test))\n",
    "            #print(f'Biased classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            \n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_test += [disparity.gamma(classify).max()]\n",
    "            \n",
    "            # Learned bayes optimal classifier\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_b = classifier.fit(X_true, y_true)                \n",
    "            #classifier_b = clone(classifier).fit(X_true, y_true)\n",
    "            acc = accuracy_score(y_test,classifier_b.predict(X_test))\n",
    "            #print(f'Learned BO classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            \n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_test += [disparity.gamma(classify).max()]\n",
    "            \n",
    "            \n",
    "            # Exact BO optimal classifier\n",
    "            #print(f'Exact BO classifier:')\n",
    "            acc = accuracy_score(y_test,exact_bo_labels_test)\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc = accuracy_score(y_true,exact_bo_labels_train)\n",
    "            #print(f'     Train accuracy = {acc}')\n",
    "\n",
    "            if apply_fairness:\n",
    "                if not is_empty:\n",
    "                    constraint = EqualizedOdds()\n",
    "                    classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none', fit_intercept = False, max_iter = 200)   \n",
    "\n",
    "    #                 classifier_mitigated_bias = GridSearch(estimator=classifier,\n",
    "    #                                                        constraints=constraint,\n",
    "    #                                                        selection_rule='tradeoff_optimization',\n",
    "    #                                                        constraint_weight=0.5,\n",
    "    #                                                        grid_size=10,\n",
    "    #                                                        grid_limit=2.0,\n",
    "    #                                                        grid_offset=None,\n",
    "    #                                                        grid=None,\n",
    "    #                                                        sample_weight_name='sample_weight')\n",
    "\n",
    "                    classifier_mitigated_bias = ThresholdOptimizer(estimator=clone(classifier_bias), constraints= 'equalized_odds', predict_method='auto')\n",
    "\n",
    "                    classifier_mitigated_bias.fit(X_bias_true, y_bias_true, sensitive_features = df_sens)\n",
    "\n",
    "                    #acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\n",
    "                    acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test, sensitive_features=sens_attr_test))\n",
    "                    #print(f'Mitigated bias classifier:')\n",
    "                    #print(f'     Test accuracy = {acc}')\n",
    "                    #acc_mitigated_test += [acc]\n",
    "                    #acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true))]\n",
    "                    #acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true, sensitive_features=df_sens))]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = df_sens)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = sens_attr_test)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_test += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    # Alternative fidelity of intervention model to no intervention model\n",
    "                    alt_fid_train = accuracy_score(classifier_mitigated_bias.predict(X_bias_true, sensitive_features = df_sens),classifier_bias.predict(X_bias_true))\n",
    "                    alt_fid_test = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_bias.predict(X_test))\n",
    "                    #print(f'Alternative fidelity of intervention model to no intervention model: train = {alt_fid_train}, test = {alt_fid_test}')\n",
    "                else:\n",
    "                    disp_mitigated_train += [np.nan]\n",
    "                    disp_mitigated_test += [np.nan]\n",
    "\n",
    "#                     acc_mitigated_train += [np.nan]\n",
    "#                     acc_mitigated_test += [np.nan]\n",
    "\n",
    "            else:\n",
    "                classifier_mitigated_bias = clone(classifier_bias)\n",
    "                classifier_mitigated_bias.fit(X_bias_true, y_bias_true)\n",
    "                \n",
    "                disp_mitigated_train += [0]\n",
    "                disp_mitigated_test += [0]\n",
    "                \n",
    "#                 acc_mitigated_train += [0]\n",
    "#                 acc_mitigated_test += [0]\n",
    "                \n",
    "                # NOTE: disparities are the same as for classifier_bias\n",
    "\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                else:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                \n",
    "            fid = accuracy_score(classifier_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "            #print(f'Test set fidelity of learned BO classifier and biased classifier: {fid}')\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj, sensitive_features = sens_attr_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min, sensitive_features = sens_attr_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test), classifier_b.predict(X_test))]\n",
    "                else:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test), classifier_b.predict(X_test))]\n",
    "            else:\n",
    "                test_maj += [np.nan]\n",
    "                test_min += [np.nan]\n",
    "                total += [np.nan]\n",
    "                \n",
    "            if verbose:\n",
    "                #print(\"Finished Iteration: \", count)\n",
    "                count +=1\n",
    "        \n",
    "        #print(f'Fidelity test maj: {test_maj}')\n",
    "        #print(f'Fidelity test min: {test_maj}')\n",
    "        \n",
    "        total_fidel_maj.append(test_maj)\n",
    "        total_fidel_min.append(test_min)\n",
    "        total_fidel.append(total)\n",
    "        \n",
    "        total_disp_bias_train.append(disp_bias_train)\n",
    "        total_disp_bo_train.append(disp_bo_train)\n",
    "        total_disp_mitigated_train.append(disp_mitigated_train)\n",
    "\n",
    "        total_disp_bias_test.append(disp_bias_test)\n",
    "        total_disp_bo_test.append(disp_bo_test)\n",
    "        total_disp_mitigated_test.append(disp_mitigated_test)\n",
    "        \n",
    "#         total_acc_bias_train.append(acc_bias_train)\n",
    "#         total_acc_bo_train.append(acc_bo_train)\n",
    "#         total_acc_mitigated_train.append(acc_mitigated_train)\n",
    "\n",
    "#         total_acc_bias_test.append(acc_bias_test)\n",
    "#         total_acc_bo_test.append(acc_bo_test)\n",
    "#         total_acc_mitigated_test.append(acc_mitigated_test)\n",
    "        \n",
    "        if verbose:\n",
    "                print(\"Finished Total Iteration: \", i+1)\n",
    "    \n",
    "    mean_fidel_maj = remove_nan(total_fidel_maj)\n",
    "    mean_fidel_min = remove_nan(total_fidel_min)\n",
    "    mean_fidel = remove_nan(total_fidel)\n",
    "    \n",
    "    mean_disp_bias_train = remove_nan(total_disp_bias_train)\n",
    "    mean_disp_bo_train = remove_nan(total_disp_bo_train)\n",
    "    mean_disp_mitigated_train = remove_nan(total_disp_mitigated_train)\n",
    "    \n",
    "    mean_disp_bias_test = remove_nan(total_disp_bias_test)\n",
    "    mean_disp_bo_test = remove_nan(total_disp_bo_test)\n",
    "    mean_disp_mitigated_test = remove_nan(total_disp_mitigated_test)\n",
    "    \n",
    "#     mean_acc_bias_train = remove_nan(total_acc_bias_train)\n",
    "#     mean_acc_bo_train = remove_nan(total_acc_bo_train)\n",
    "#     mean_acc_mitigated_train = remove_nan(total_acc_mitigated_train)\n",
    "    \n",
    "#     mean_acc_bias_test = remove_nan(total_acc_bias_test)\n",
    "#     mean_acc_bo_test = remove_nan(total_acc_bo_test)\n",
    "#     mean_acc_mitigated_test = remove_nan(total_acc_mitigated_test)\n",
    "    \n",
    "    y_err_fidel_maj = remove_nan_std(total_fidel_maj)\n",
    "    y_err_fidel_min = remove_nan_std(total_fidel_min)\n",
    "    y_err_fidel = remove_nan_std(total_fidel)\n",
    "    \n",
    "    \n",
    "    df_disp = pd.DataFrame({\"Biased Train\" : mean_disp_bias_train,\n",
    "                       \"BO Train\" : mean_disp_bo_train,\n",
    "                       \"Mitigated Train\" : mean_disp_mitigated_train,\n",
    "                       \"Biased Test\" : mean_disp_bias_test,\n",
    "                       \"BO Test\" : mean_disp_bo_test,\n",
    "                       \"Mitigated Test\" : mean_disp_mitigated_test})\n",
    "    \n",
    "#     df_acc = pd.DataFrame({\"Biased Train\" : mean_acc_bias_train,\n",
    "#                        \"BO Train\" : mean_acc_bo_train,\n",
    "#                        \"Mitigated Train\" : mean_acc_mitigated_train,\n",
    "#                        \"Biased Test\" : mean_acc_bias_test,\n",
    "#                        \"BO Test\" : mean_acc_bo_test,\n",
    "#                        \"Mitigated Test\" : mean_acc_mitigated_test})\n",
    "   \n",
    "    return bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp#, df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71a951ee-acd1-4bf9-bd95-ba9acc383063",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train\n",
      "Diff:  0.008583333333333332\n",
      "Num Flipped Maj:  9594 \tRate:  0.39975\n",
      "\n",
      "generating test\n",
      "Diff:  -0.0010000000000000009\n",
      "Pos Min Flipped:  2387 \tRate:  0.3978333333333333\n",
      "Beta:  0.0 \n",
      "\n",
      "Pos Min Flipped:  0 \tRate:  0.0\n",
      "Beta:  0.05 \n",
      "\n",
      "Pos Min Flipped:  296 \tRate:  0.04933333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-dbc87fb4001b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlabel_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disp_label_noise_no_inter.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-a1b1496da951>\u001b[0m in \u001b[0;36mlabel_noise\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0mclassifier_mitigated_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThresholdOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'equalized_odds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                     \u001b[0mclassifier_mitigated_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0;31m#acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sensitive_features, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         self.interpolated_thresholder_ = threshold_optimization_method(\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0msensitive_feature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36m_threshold_optimization_for_equalized_odds\u001b[0;34m(self, sensitive_features, labels, scores)\u001b[0m\n\u001b[1;32m    535\u001b[0m         ) in data_grouped_by_sensitive_feature:\n\u001b[1;32m    536\u001b[0m             roc_convex_hull = _tradeoff_curve(\n\u001b[0;32m--> 537\u001b[0;31m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_feature_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m             )\n\u001b[1;32m    539\u001b[0m             self._tradeoff_curve[sensitive_feature_value] = _interpolate_curve(\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_tradeoff_curve\u001b[0;34m(data, sensitive_feature_value, flip, x_metric, y_metric)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m     95\u001b[0m     points_sorted = _calculate_tradeoff_points(\n\u001b[0;32m---> 96\u001b[0;31m         data, sensitive_feature_value, flip=flip, x_metric=x_metric, y_metric=y_metric)\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mpoints_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_points_to_get_convex_hull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mconvex_hull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'operation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_calculate_tradeoff_points\u001b[0;34m(data, sensitive_feature_value, flip, x_metric, y_metric)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mtrue_positives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_positive\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mtrue_negatives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             false_negatives=count[1])\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0moperations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflipped_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_extend_confusion_matrix\u001b[0;34m(true_positives, false_positives, true_negatives, false_negatives)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mpositives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mnegatives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_negatives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrue_negatives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \"\"\"\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df = \\\n",
    "label_noise(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = False, inter = False)\n",
    "\n",
    "df.to_csv('disp_label_noise_no_inter.csv', index = True)\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel,\n",
    "                                y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T,\n",
    "                      columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_res.to_csv(f'fid_label_noise_no_inter.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84b4cf46-bd7e-4c96-af0b-d10298355ab9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train\n",
      "Diff:  0.008583333333333332\n",
      "Num Flipped Maj:  9594 \tRate:  0.39975\n",
      "Num Flipped Min Neg:  1195 \tRate:  0.3941292875989446\n",
      "\n",
      "generating test\n",
      "Diff:  -0.0010000000000000009\n",
      "Pos Min Flipped:  1159 \tRate:  0.39049865229110514\n",
      "Beta:  0.0 \n",
      "\n",
      "Pos Min Flipped:  0 \tRate:  0.0\n",
      "Beta:  0.05 \n",
      "\n",
      "Pos Min Flipped:  143 \tRate:  0.04818059299191375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-63bf2b9e792b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlabel_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disp_label_noise_inter.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-a1b1496da951>\u001b[0m in \u001b[0;36mlabel_noise\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# Learned bayes optimal classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mclassifier_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;31m#classifier_b = clone(classifier).fit(X_true, y_true)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    182\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'multiclass'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df = \\\n",
    "label_noise(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = False, inter = True)\n",
    "\n",
    "df.to_csv('disp_label_noise_inter.csv', index = True)\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel,\n",
    "                                y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T,\n",
    "                      columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_res.to_csv(f'fid_label_noise_inter.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0392aa7e-446f-406f-8bf1-44b8ad247ffb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  0.20808333333333334\n",
      "Num Flipped Maj:  9594 \tRate:  0.39975\n",
      "Num Flipped Min Neg:  1195 \tRate:  0.3941292875989446\n",
      "Diff:  0.19770833333333326\n",
      "Pos Min Flipped:  1159 \tRate:  0.39049865229110514\n",
      "Beta:  0.0 \n",
      "\n",
      "Pos Min Flipped:  0 \tRate:  0.0\n",
      "Beta:  0.05 \n",
      "\n",
      "Pos Min Flipped:  143 \tRate:  0.04818059299191375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e1d78af461c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlabel_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disp_label_noise_diff_base.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-a1b1496da951>\u001b[0m in \u001b[0;36mlabel_noise\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    190\u001b[0m                     \u001b[0mclassifier_mitigated_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThresholdOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'equalized_odds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                     \u001b[0mclassifier_mitigated_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0;31m#acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sensitive_features, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         self.interpolated_thresholder_ = threshold_optimization_method(\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0msensitive_feature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36m_threshold_optimization_for_equalized_odds\u001b[0;34m(self, sensitive_features, labels, scores)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msensitive_feature_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tradeoff_curve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             roc_result = self._tradeoff_curve[\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0msensitive_feature_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             ].transpose()[i_best_EO]\n\u001b[1;32m    586\u001b[0m             \u001b[0;31m# p_ignore * x_best represent the diagonal of the ROC plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(self, copy, *args)\u001b[0m\n\u001b[1;32m   2710\u001b[0m                 \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m             result = self._constructor(\n\u001b[0;32m-> 2712\u001b[0;31m                 \u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2713\u001b[0m             )\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                 ]\n\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1658\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0mftypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0mftypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mftype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"{dtype}:{self._ftype}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_struct_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_align\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df = \\\n",
    "label_noise(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = True, inter = True)\n",
    "\n",
    "df.to_csv('disp_label_noise_diff_base.csv', index = True)\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T, columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_res.to_csv(f'fid_label_noise_diff_base.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5dce5-46b4-4d5c-a267-772edce57f04",
   "metadata": {},
   "source": [
    "## Feature Noise/Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de841c3f-270f-44f2-ae25-a1e8c7761b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_noise_num(df, feature, eta, eps = 1):\n",
    "    feats = df[feature].values\n",
    "    #print('Before:', df_synthetic['outcome'].value_counts())\n",
    "    num_flipped = 0\n",
    "    for i in range(len(feats)):\n",
    "        if random.uniform(0,1) <= eta:\n",
    "            feats[i] = 0\n",
    "            num_flipped += 1\n",
    "    df[feature] = feats\n",
    "    print('Num Flipped: ', num_flipped, \"\\tRate: \", num_flipped / len(df))\n",
    "    return df\n",
    "\n",
    "# measurement bias\n",
    "def get_biased_data(df, eps, inter):\n",
    "    df_majority = df[df['cat'] == 1]\n",
    "    df_minority = df[df['cat'] == 0]\n",
    "    \n",
    "    if inter:\n",
    "    \n",
    "        # unfavored group with negative label\n",
    "        df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "        # unfavored group with positive label (preferred)\n",
    "        df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "\n",
    "        # data frame without positively labeled examples from minority class\n",
    "        df_total = pd.concat([df_majority, df_minority_negative])\n",
    "\n",
    "        # under-sampling process\n",
    "        df_bias = inject_noise_num(df_minority_positive, 'num1', eps)\n",
    "\n",
    "        # combine undersampled and original favored class to create dataset\n",
    "        df_concat = pd.concat([df_total,df_bias])\n",
    "    \n",
    "    else:\n",
    "        # under-sampling process\n",
    "        df_bias = inject_noise_num(df_minority, 'num1', eps)\n",
    "        # combine undersampled and original favored class to create dataset\n",
    "        df_concat = pd.concat([df_majority,df_bias])\n",
    "    \n",
    "    return df_concat.sample(frac=1, random_state = 42) # permute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8940a097-802a-41ea-a450-e3dd7bf94dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement(r, n, apply_fairness = True, verbose = False, num_iters = 10, inter = False, diff_base = False):\n",
    "    \n",
    "    empty_dict = dict()\n",
    "    empty_dict['0.9'] = 0\n",
    "    empty_dict['0.95'] = 0\n",
    "    \n",
    "    total_fidel_maj = []\n",
    "    total_fidel_min = []\n",
    "    total_fidel = []\n",
    "    \n",
    "    total_disp_bias_train = []\n",
    "    total_disp_bo_train = []\n",
    "    total_disp_mitigated_train = []\n",
    "    \n",
    "    total_disp_bias_test = []\n",
    "    total_disp_bo_test = []\n",
    "    total_disp_mitigated_test = []\n",
    "    \n",
    "    total_acc_bias_train = []\n",
    "    total_acc_bo_train = []\n",
    "    total_acc_mitigated_train = []\n",
    "    \n",
    "    total_acc_bias_test = []\n",
    "    total_acc_bo_test = []\n",
    "    total_acc_mitigated_test = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "    \n",
    "        bias_amts = np.divide(list(range(0,11,1)),10)\n",
    "\n",
    "        test_maj = []\n",
    "        test_min = []\n",
    "        total = []\n",
    "        \n",
    "        disp_bias_train = []\n",
    "        disp_bo_train = []\n",
    "        disp_mitigated_train = []\n",
    "        \n",
    "        disp_bias_test = []\n",
    "        disp_bo_test = []\n",
    "        disp_mitigated_test = []\n",
    "        \n",
    "        acc_bias_train = []\n",
    "        acc_bo_train = []\n",
    "        acc_mitigated_train = []\n",
    "\n",
    "        acc_bias_test = []\n",
    "        acc_bo_test = []\n",
    "        acc_mitigated_test = []\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        if diff_base: \n",
    "            outcome_continuous, df_synthetic = true_label_generation(r=r, eta=eta, n=2*n, maj_means =[0.7,0.7,0.7])\n",
    "        else: outcome_continuous, df_synthetic = true_label_generation(r=r, eta=eta, n=2*n)        \n",
    "        \n",
    "        threshold = 0.5\n",
    "        exact_bo_labels = np.where(outcome_continuous < threshold, 0, 1)\n",
    "        exact_bo_labels_train = np.array(exact_bo_labels[range(0,n)])\n",
    "        exact_bo_labels_test = np.array(exact_bo_labels[range(n,len(df_synthetic))])\n",
    "        \n",
    "        # split into train and test\n",
    "        df_train = df_synthetic.loc[range(0,n), :]\n",
    "        \n",
    "        df_train_transf, maj_list, min_list = transform(df_train, True, True)\n",
    "        \n",
    "        df_test = df_synthetic.loc[range(n, len(df_synthetic)),:]\n",
    "        df_maj = df_test[df_test['cat'] == 1]\n",
    "        df_min = df_test[df_test['cat'] == 0]\n",
    "        \n",
    "        df_test_transf, maj_list, min_list = transform(df_test, True, False)\n",
    "        \n",
    "        df_test_maj = df_test_transf.loc[maj_list]\n",
    "        df_test_min = df_test_transf.loc[min_list]\n",
    "\n",
    "        # format training data\n",
    "        X_true = df_train_transf.iloc[:, :-2].values\n",
    "        y_true = df_train_transf.iloc[:, -1].values\n",
    "        \n",
    "        # format test data\n",
    "        X_test = df_test_transf.iloc[:, :-2].values\n",
    "        X_test_maj = df_test_maj.iloc[:, :-2].values\n",
    "        X_test_min = df_test_min.iloc[:, :-2].values\n",
    "        y_test = df_test_transf.iloc[:, -1].values\n",
    "        y_test_maj = df_test_maj.iloc[:, -1].values\n",
    "        y_test_min = df_test_min.iloc[:, -1].values\n",
    "        \n",
    "        sens_attr_test = df_test['cat']\n",
    "        sens_attr_maj = df_maj['cat']\n",
    "        sens_attr_min = df_min['cat']\n",
    "        \n",
    "        \n",
    "        for beta in bias_amts:\n",
    "            \n",
    "            if i == 0: print(\"Beta: \", beta, '\\n')\n",
    "\n",
    "            df_train_copy = df_train.copy()\n",
    "\n",
    "            df_majority = df_train_copy[df_train_copy['cat'] == 1]\n",
    "            df_minority = df_train_copy[df_train_copy['cat'] == 0]\n",
    "\n",
    "            # unfavored group with negative label\n",
    "            df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "            # unfavored group with positive label (preferred)\n",
    "            df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "\n",
    "            # data frame without positively labeled examples from minority class\n",
    "            df_total = pd.concat([df_majority, df_minority_negative])\n",
    "\n",
    "            # under-sampling process\n",
    "            df_undersampled, is_empty = under(df_minority_positive, 1)\n",
    "            \n",
    "            if is_empty:\n",
    "                empty_dict[str(1-beta)] += 1\n",
    "                print(empty_dict)\n",
    "\n",
    "            # combine undersampled and original favored class to create dataset\n",
    "            df_concat1 = pd.concat([df_total,df_undersampled])\n",
    "            \n",
    "            df_concat = get_biased_data(df_concat1, beta, inter)\n",
    "\n",
    "            # format data\n",
    "            X_bias_true, y_bias_true, df_sens = transform(df_concat)\n",
    "            \n",
    "            # model trained on biased data\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_bias = classifier.fit(X_bias_true, y_bias_true)\n",
    "            \n",
    "            acc = accuracy_score(y_test,classifier_bias.predict(X_test))\n",
    "            #print(f'Biased classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc_bias_test += [acc]\n",
    "            acc_bias_train += [accuracy_score(y_bias_true, classifier_bias.predict(X_bias_true))]\n",
    "            \n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_test += [disparity.gamma(classify).max()]\n",
    "            \n",
    "            # Learned bayes optimal classifier\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_b = classifier.fit(X_true, y_true)                \n",
    "            #classifier_b = clone(classifier).fit(X_true, y_true)\n",
    "            acc = accuracy_score(y_test,classifier_b.predict(X_test))\n",
    "            #print(f'Learned BO classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc_bo_test += [acc]\n",
    "            acc_bo_train += [accuracy_score(y_bias_true, classifier_b.predict(X_bias_true))]\n",
    "            \n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_test += [disparity.gamma(classify).max()]\n",
    "            \n",
    "            \n",
    "            # Exact BO optimal classifier\n",
    "            #print(f'Exact BO classifier:')\n",
    "            acc = accuracy_score(y_test,exact_bo_labels_test)\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc = accuracy_score(y_true,exact_bo_labels_train)\n",
    "            #print(f'     Train accuracy = {acc}')\n",
    "\n",
    "            if apply_fairness:\n",
    "                if not is_empty:\n",
    "                    constraint = EqualizedOdds()\n",
    "                    classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none', fit_intercept = False, max_iter = 200)   \n",
    "\n",
    "    #                 classifier_mitigated_bias = GridSearch(estimator=classifier,\n",
    "    #                                                        constraints=constraint,\n",
    "    #                                                        selection_rule='tradeoff_optimization',\n",
    "    #                                                        constraint_weight=0.5,\n",
    "    #                                                        grid_size=10,\n",
    "    #                                                        grid_limit=2.0,\n",
    "    #                                                        grid_offset=None,\n",
    "    #                                                        grid=None,\n",
    "    #                                                        sample_weight_name='sample_weight')\n",
    "\n",
    "                    classifier_mitigated_bias = ThresholdOptimizer(estimator=clone(classifier_bias), constraints= 'equalized_odds', predict_method='auto')\n",
    "\n",
    "                    classifier_mitigated_bias.fit(X_bias_true, y_bias_true, sensitive_features = df_sens)\n",
    "\n",
    "                    #acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\n",
    "                    acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test, sensitive_features=sens_attr_test))\n",
    "                    #print(f'Mitigated bias classifier:')\n",
    "                    #print(f'     Test accuracy = {acc}')\n",
    "                    acc_mitigated_test += [acc]\n",
    "                    #acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true))]\n",
    "                    acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true, sensitive_features=df_sens))]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = df_sens)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = sens_attr_test)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_test += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    # Alternative fidelity of intervention model to no intervention model\n",
    "                    alt_fid_train = accuracy_score(classifier_mitigated_bias.predict(X_bias_true, sensitive_features = df_sens),classifier_bias.predict(X_bias_true))\n",
    "                    alt_fid_test = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_bias.predict(X_test))\n",
    "                    #print(f'Alternative fidelity of intervention model to no intervention model: train = {alt_fid_train}, test = {alt_fid_test}')\n",
    "                else:\n",
    "                    print('huh')\n",
    "                    disp_mitigated_train += [np.nan]\n",
    "                    disp_mitigated_test += [np.nan]\n",
    "\n",
    "                    acc_mitigated_train += [np.nan]\n",
    "                    acc_mitigated_test += [np.nan]\n",
    "\n",
    "            else:\n",
    "                classifier_mitigated_bias = clone(classifier_bias)\n",
    "                classifier_mitigated_bias.fit(X_bias_true, y_bias_true)\n",
    "                \n",
    "                disp_mitigated_train += [0]\n",
    "                disp_mitigated_test += [0]\n",
    "                \n",
    "                acc_mitigated_train += [0]\n",
    "                acc_mitigated_test += [0]\n",
    "                \n",
    "                # NOTE: disparities are the same as for classifier_bias\n",
    "\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                else:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                \n",
    "            fid = accuracy_score(classifier_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "            #print(f'Test set fidelity of learned BO classifier and biased classifier: {fid}')\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj, sensitive_features = sens_attr_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min, sensitive_features = sens_attr_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test), classifier_b.predict(X_test))]\n",
    "                else:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test), classifier_b.predict(X_test))]\n",
    "            else:\n",
    "                test_maj += [np.nan]\n",
    "                test_min += [np.nan]\n",
    "                total += [np.nan]\n",
    "                \n",
    "            if verbose:\n",
    "                #print(\"Finished Iteration: \", count)\n",
    "                count +=1\n",
    "        \n",
    "        #print(f'Fidelity test maj: {test_maj}')\n",
    "        #print(f'Fidelity test min: {test_maj}')\n",
    "        \n",
    "        total_fidel_maj.append(test_maj)\n",
    "        total_fidel_min.append(test_min)\n",
    "        total_fidel.append(total)\n",
    "        \n",
    "        total_disp_bias_train.append(disp_bias_train)\n",
    "        total_disp_bo_train.append(disp_bo_train)\n",
    "        total_disp_mitigated_train.append(disp_mitigated_train)\n",
    "\n",
    "        total_disp_bias_test.append(disp_bias_test)\n",
    "        total_disp_bo_test.append(disp_bo_test)\n",
    "        total_disp_mitigated_test.append(disp_mitigated_test)\n",
    "        \n",
    "        total_acc_bias_train.append(acc_bias_train)\n",
    "        total_acc_bo_train.append(acc_bo_train)\n",
    "        total_acc_mitigated_train.append(acc_mitigated_train)\n",
    "\n",
    "        total_acc_bias_test.append(acc_bias_test)\n",
    "        total_acc_bo_test.append(acc_bo_test)\n",
    "        total_acc_mitigated_test.append(acc_mitigated_test)\n",
    "        \n",
    "        if verbose:\n",
    "                print(\"Finished Total Iteration: \", i+1)\n",
    "    \n",
    "    mean_fidel_maj = np.mean(total_fidel_maj, axis = 0)\n",
    "    mean_fidel_min = np.mean(total_fidel_min, axis = 0)\n",
    "    mean_fidel = np.mean(total_fidel, axis = 0)\n",
    "    \n",
    "    mean_disp_bias_train = np.mean(total_disp_bias_train, axis = 0)\n",
    "    mean_disp_bo_train = np.mean(total_disp_bo_train, axis = 0)\n",
    "    mean_disp_mitigated_train = np.mean(total_disp_mitigated_train, axis = 0)\n",
    "    \n",
    "    mean_disp_bias_test = np.mean(total_disp_bias_test, axis = 0)\n",
    "    mean_disp_bo_test = np.mean(total_disp_bo_test, axis = 0)\n",
    "    mean_disp_mitigated_test = np.mean(total_disp_mitigated_test, axis = 0)\n",
    "    \n",
    "    mean_acc_bias_train = np.mean(total_acc_bias_train, axis = 0)\n",
    "    mean_acc_bo_train = np.mean(total_acc_bo_train, axis = 0)\n",
    "    mean_acc_mitigated_train = np.mean(total_acc_mitigated_train, axis = 0)\n",
    "    \n",
    "    mean_acc_bias_test = np.mean(total_acc_bias_test, axis = 0)\n",
    "    mean_acc_bo_test = np.mean(total_acc_bo_test, axis = 0)\n",
    "    mean_acc_mitigated_test = np.mean(total_acc_mitigated_test, axis = 0)\n",
    "    \n",
    "    y_err_fidel_maj = np.std(total_fidel_maj, axis = 0)\n",
    "    y_err_fidel_min = np.std(total_fidel_min, axis = 0)\n",
    "    y_err_fidel = np.std(total_fidel, axis = 0)\n",
    "    \n",
    "    \n",
    "    df_disp = pd.DataFrame({\"Biased Train\" : mean_disp_bias_train,\n",
    "                       \"BO Train\" : mean_disp_bo_train,\n",
    "                       \"Mitigated Train\" : mean_disp_mitigated_train,\n",
    "                       \"Biased Test\" : mean_disp_bias_test,\n",
    "                       \"BO Test\" : mean_disp_bo_test,\n",
    "                       \"Mitigated Test\" : mean_disp_mitigated_test})\n",
    "    \n",
    "    df_acc = pd.DataFrame({\"Biased Train\" : mean_acc_bias_train,\n",
    "                       \"BO Train\" : mean_acc_bo_train,\n",
    "                       \"Mitigated Train\" : mean_acc_mitigated_train,\n",
    "                       \"Biased Test\" : mean_acc_bias_test,\n",
    "                       \"BO Test\" : mean_acc_bo_test,\n",
    "                       \"Mitigated Test\" : mean_acc_mitigated_test})\n",
    "   \n",
    "    return bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeb42019-2897-46ba-82c2-dc1bf85608d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc155cbf-30ac-4b4b-ae71-ecbb2ef26f6c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  0.008458333333333345\n",
      "Beta:  0.0 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Num Flipped:  0 \tRate:  0.0\n",
      "Beta:  0.1 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Num Flipped:  612 \tRate:  0.10330857528696827\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6ed73819fa0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_disp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmeasurement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias_amts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel_maj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel_min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel_maj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel_min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-880180e7caec>\u001b[0m in \u001b[0;36mmeasurement\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mclassifier_mitigated_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThresholdOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'equalized_odds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                     \u001b[0mclassifier_mitigated_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0;31m#acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sensitive_features, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         self.interpolated_thresholder_ = threshold_optimization_method(\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0msensitive_feature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36m_threshold_optimization_for_equalized_odds\u001b[0;34m(self, sensitive_features, labels, scores)\u001b[0m\n\u001b[1;32m    535\u001b[0m         ) in data_grouped_by_sensitive_feature:\n\u001b[1;32m    536\u001b[0m             roc_convex_hull = _tradeoff_curve(\n\u001b[0;32m--> 537\u001b[0;31m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_feature_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m             )\n\u001b[1;32m    539\u001b[0m             self._tradeoff_curve[sensitive_feature_value] = _interpolate_curve(\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_tradeoff_curve\u001b[0;34m(data, sensitive_feature_value, flip, x_metric, y_metric)\u001b[0m\n\u001b[1;32m     95\u001b[0m     points_sorted = _calculate_tradeoff_points(\n\u001b[1;32m     96\u001b[0m         data, sensitive_feature_value, flip=flip, x_metric=x_metric, y_metric=y_metric)\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mpoints_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_points_to_get_convex_hull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mconvex_hull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'operation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvex_hull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_filter_points_to_get_convex_hull\u001b[0;34m(points_sorted)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# whether or not to drop r1. Instead of delta_y/delta_x we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# multiplied both sides of the inequation by the delta_xs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mr0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mr0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mr0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mr0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0;31m# drop r1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mselected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc = \\\n",
    "measurement(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = False, inter = False)\n",
    "\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T, columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_disp.to_csv(f'post_disp_featmissing_no_inter.csv', index = True)\n",
    "df_res.to_csv(f'post_fid_featmissing_no_inter.csv', index = True)\n",
    "df_acc.to_csv(f'post_acc_featmissing_no_inter.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c795647-4294-4493-b70f-d13db39da17a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  0.008458333333333345\n",
      "Beta:  0.0 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Num Flipped:  0 \tRate:  0.0\n",
      "Beta:  0.1 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Num Flipped:  297 \tRate:  0.10181693520740487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-87f85c9d70ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_disp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmeasurement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias_amts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel_maj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel_min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel_maj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel_min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-880180e7caec>\u001b[0m in \u001b[0;36mmeasurement\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mclassifier_mitigated_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThresholdOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'equalized_odds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                     \u001b[0mclassifier_mitigated_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0;31m#acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sensitive_features, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         self.interpolated_thresholder_ = threshold_optimization_method(\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0msensitive_feature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36m_threshold_optimization_for_equalized_odds\u001b[0;34m(self, sensitive_features, labels, scores)\u001b[0m\n\u001b[1;32m    535\u001b[0m         ) in data_grouped_by_sensitive_feature:\n\u001b[1;32m    536\u001b[0m             roc_convex_hull = _tradeoff_curve(\n\u001b[0;32m--> 537\u001b[0;31m                 \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_feature_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m             )\n\u001b[1;32m    539\u001b[0m             self._tradeoff_curve[sensitive_feature_value] = _interpolate_curve(\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_tradeoff_curve\u001b[0;34m(data, sensitive_feature_value, flip, x_metric, y_metric)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m     95\u001b[0m     points_sorted = _calculate_tradeoff_points(\n\u001b[0;32m---> 96\u001b[0;31m         data, sensitive_feature_value, flip=flip, x_metric=x_metric, y_metric=y_metric)\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mpoints_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_points_to_get_convex_hull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mconvex_hull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'operation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_calculate_tradeoff_points\u001b[0;34m(data, sensitive_feature_value, flip, x_metric, y_metric)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mtrue_positives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_positive\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mtrue_negatives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             false_negatives=count[1])\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0moperations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflipped_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_extend_confusion_matrix\u001b[0;34m(true_positives, false_positives, true_negatives, false_negatives)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mpositives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mnegatives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_negatives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrue_negatives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc = \\\n",
    "measurement(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = False, inter = True)\n",
    "\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T, columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_disp.to_csv(f'post_disp_featmissing_inter.csv', index = True)\n",
    "df_res.to_csv(f'post_fid_featmissing_inter.csv', index = True)\n",
    "df_acc.to_csv(f'post_acc_featmissing_inter.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48847578-9444-4f60-a690-6b1277c34644",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  0.2084166666666667\n",
      "Beta:  0.0 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Num Flipped:  0 \tRate:  0.0\n",
      "Beta:  0.1 \n",
      "\n",
      "Total Deleted:  0 \t % Deleted:  0.0\n",
      "Num Flipped:  297 \tRate:  0.10181693520740487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-54510e79cb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_disp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmeasurement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fairness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias_amts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel_maj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel_min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fidel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel_maj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel_min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_err_fidel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-880180e7caec>\u001b[0m in \u001b[0;36mmeasurement\u001b[0;34m(r, n, apply_fairness, verbose, num_iters, inter, diff_base)\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mclassifier_mitigated_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThresholdOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'equalized_odds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                     \u001b[0mclassifier_mitigated_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bias_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0;31m#acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sensitive_features, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         self.interpolated_thresholder_ = threshold_optimization_method(\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0msensitive_feature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_threshold_optimizer.py\u001b[0m in \u001b[0;36m_threshold_optimization_for_equalized_odds\u001b[0;34m(self, sensitive_features, labels, scores)\u001b[0m\n\u001b[1;32m    538\u001b[0m             )\n\u001b[1;32m    539\u001b[0m             self._tradeoff_curve[sensitive_feature_value] = _interpolate_curve(\n\u001b[0;32m--> 540\u001b[0;31m                 \u001b[0mroc_convex_hull\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"operation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m             )\n\u001b[1;32m    542\u001b[0m             y_values[sensitive_feature_value] = self._tradeoff_curve[\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/fairlearn/postprocessing/_tradeoff_curve_utilities.py\u001b[0m in \u001b[0;36m_interpolate_curve\u001b[0;34m(data, x_col, y_col, content_col, x_grid)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_distance_from_next_data_point\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mx_distance_between_data_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata_transpose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata_transpose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         dict_list.append({\n\u001b[1;32m    189\u001b[0m             \u001b[0mx_col\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4402\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4404\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 50\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp, df_acc = \\\n",
    "measurement(r = r, n = n, apply_fairness=True,verbose=True, num_iters=num_iters, diff_base = True, inter = True)\n",
    "\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T, columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_disp.to_csv(f'post_disp_featmissing_diff_base.csv', index = True)\n",
    "df_res.to_csv(f'post_fid_featmissing_diff_base.csv', index = True)\n",
    "df_acc.to_csv(f'post_acc_featmissing_diff_base.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825edf34-b121-4d75-b519-3cb15e028bbc",
   "metadata": {},
   "source": [
    "## Different Base Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ba98002-8e7d-47fa-ba13-5eb67b749a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_base_rates(r, n, verbose = False, num_iters = 10):\n",
    "    \n",
    "    beta = 0.6\n",
    "    bias_amts = [-0.5, -0.4, -0.3, -0.2, -0.1, 0, .1, .2, .3, .4, .5]\n",
    "    \n",
    "    total_fidel_maj = []\n",
    "    total_fidel_min = []\n",
    "    total_fidel = []\n",
    "    \n",
    "    total_disp_bias_train = []\n",
    "    total_disp_bo_train = []\n",
    "    total_disp_mitigated_train = []\n",
    "    \n",
    "    total_disp_bias_test = []\n",
    "    total_disp_bo_test = []\n",
    "    total_disp_mitigated_test = []\n",
    "    \n",
    "    vals = [-4, -1.7, -1.1, -0.7, -0.3, 0, 0.35, 0.7, 1.15, 1.75, 4]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        test_maj = []\n",
    "        test_min = []\n",
    "        total = []\n",
    "        \n",
    "        disp_bias_train = []\n",
    "        disp_bo_train = []\n",
    "        disp_mitigated_train = []\n",
    "        \n",
    "        disp_bias_test = []\n",
    "        disp_bo_test = []\n",
    "        disp_mitigated_test = []\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for diff in vals:\n",
    "            \n",
    "            arr = np.ones(3)*diff\n",
    "            outcome_continuous, df_synthetic = true_label_generation(r=r, eta=eta, n=2*n, maj_means = arr)\n",
    "\n",
    "            threshold = 0.5\n",
    "            exact_bo_labels = np.where(outcome_continuous < threshold, 0, 1)\n",
    "            exact_bo_labels_train = np.array(exact_bo_labels[range(0,n)])\n",
    "            exact_bo_labels_test = np.array(exact_bo_labels[range(n,len(df_synthetic))])\n",
    "\n",
    "            # split into train and test\n",
    "            df_train = df_synthetic.loc[range(0,n), :]\n",
    "\n",
    "            df_train_transf, maj_list, min_list = transform(df_train, True, True)\n",
    "\n",
    "            df_test = df_synthetic.loc[range(n, len(df_synthetic)),:]\n",
    "            df_maj = df_test[df_test['cat'] == 1]\n",
    "            df_min = df_test[df_test['cat'] == 0]\n",
    "            df_test_transf, maj_list, min_list = transform(df_test, True, False)\n",
    "\n",
    "            df_test_maj = df_test_transf.loc[maj_list]\n",
    "            df_test_min = df_test_transf.loc[min_list]\n",
    "\n",
    "            # format training data\n",
    "            X_true = df_train_transf.iloc[:, :-2].values\n",
    "            y_true = df_train_transf.iloc[:, -1].values\n",
    "\n",
    "            # format test data\n",
    "            X_test = df_test_transf.iloc[:, :-2].values\n",
    "            X_test_maj = df_test_maj.iloc[:, :-2].values\n",
    "            X_test_min = df_test_min.iloc[:, :-2].values\n",
    "            y_test = df_test_transf.iloc[:, -1].values\n",
    "            y_test_maj = df_test_maj.iloc[:, -1].values\n",
    "            y_test_min = df_test_min.iloc[:, -1].values\n",
    "\n",
    "            sens_attr_test = df_test['cat']\n",
    "            sens_attr_maj = df_maj['cat']\n",
    "            sens_attr_min = df_min['cat']\n",
    "\n",
    "            df_train_copy = df_train.copy()\n",
    "\n",
    "            df_majority = df_train_copy[df_train_copy['cat'] == 1]\n",
    "            df_minority = df_train_copy[df_train_copy['cat'] == 0]\n",
    "\n",
    "            # unfavored group with negative label\n",
    "            df_minority_negative = df_minority[df_minority['outcome'] == 0.0]\n",
    "\n",
    "            # unfavored group with positive label (preferred)\n",
    "            df_minority_positive = df_minority[df_minority['outcome'] == 1.0]\n",
    "\n",
    "            # data frame without positively labeled examples from minority class\n",
    "            df_total = pd.concat([df_majority, df_minority_negative])\n",
    "\n",
    "            # under-sampling process\n",
    "            df_undersampled, is_empty = under(df_minority_positive, beta)\n",
    "            \n",
    "            if is_empty:\n",
    "                print('huh')\n",
    "\n",
    "            # combine undersampled and original favored class to create dataset\n",
    "            df_concat = pd.concat([df_total,df_undersampled]).sample(frac=1, random_state = 42)\n",
    "\n",
    "            # format data\n",
    "            X_bias_true, y_bias_true, df_sens = transform(df_concat)\n",
    "\n",
    "            # model trained on biased data\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_bias = classifier.fit(X_bias_true, y_bias_true)\n",
    "\n",
    "            acc = accuracy_score(y_test,classifier_bias.predict(X_test))\n",
    "            #print(f'Biased classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "\n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_bias\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bias_test += [disparity.gamma(classify).max()]\n",
    "\n",
    "            # Learned bayes optimal classifier\n",
    "            classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none')\n",
    "            classifier_b = classifier.fit(X_true, y_true)                \n",
    "            #classifier_b = clone(classifier).fit(X_true, y_true)\n",
    "            acc = accuracy_score(y_test,classifier_b.predict(X_test))\n",
    "            #print(f'Learned BO classifier:')\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "\n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "            #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "            m = classifier_b\n",
    "            def classify(X): return m.predict(X)\n",
    "            error = ErrorRate()\n",
    "            error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            disparity = EqualizedOdds()\n",
    "            disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "            #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "            #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "            disp_bo_test += [disparity.gamma(classify).max()]\n",
    "\n",
    "\n",
    "            # Exact BO optimal classifier\n",
    "            #print(f'Exact BO classifier:')\n",
    "            acc = accuracy_score(y_test,exact_bo_labels_test)\n",
    "            #print(f'     Test accuracy = {acc}')\n",
    "            acc = accuracy_score(y_true,exact_bo_labels_train)\n",
    "            #print(f'     Train accuracy = {acc}')\n",
    "            \n",
    "            apply_fairness = True\n",
    "            \n",
    "            if apply_fairness:\n",
    "                if not is_empty:\n",
    "                    constraint = EqualizedOdds()\n",
    "                    classifier = LogisticRegression(solver = 'lbfgs', random_state = 42, penalty = 'none', fit_intercept = False, max_iter = 200)   \n",
    "\n",
    "    #                 classifier_mitigated_bias = GridSearch(estimator=classifier,\n",
    "    #                                                        constraints=constraint,\n",
    "    #                                                        selection_rule='tradeoff_optimization',\n",
    "    #                                                        constraint_weight=0.5,\n",
    "    #                                                        grid_size=10,\n",
    "    #                                                        grid_limit=2.0,\n",
    "    #                                                        grid_offset=None,\n",
    "    #                                                        grid=None,\n",
    "    #                                                        sample_weight_name='sample_weight')\n",
    "\n",
    "                    classifier_mitigated_bias = ThresholdOptimizer(estimator=clone(classifier_bias), constraints= 'equalized_odds', predict_method='auto')\n",
    "\n",
    "                    classifier_mitigated_bias.fit(X_bias_true, y_bias_true, sensitive_features = df_sens)\n",
    "\n",
    "                    #acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test))\n",
    "                    acc = accuracy_score(y_test,classifier_mitigated_bias.predict(X_test, sensitive_features=sens_attr_test))\n",
    "                    #print(f'Mitigated bias classifier:')\n",
    "                    #print(f'     Test accuracy = {acc}')\n",
    "                    #acc_mitigated_test += [acc]\n",
    "                    #acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true))]\n",
    "                    #acc_mitigated_train += [accuracy_score(y_bias_true, classifier_mitigated_bias.predict(X_bias_true, sensitive_features=df_sens))]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = df_sens)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_bias_true, pd.Series(y_bias_true), sensitive_features=df_sens)\n",
    "                    #print(f'     Train error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Train disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_train += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    m = classifier_mitigated_bias\n",
    "                    def classify(X): return m.predict(X, sensitive_features = sens_attr_test)\n",
    "                    error = ErrorRate()\n",
    "                    error.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    disparity = EqualizedOdds()\n",
    "                    disparity.load_data(X_test, pd.Series(y_test), sensitive_features=sens_attr_test)\n",
    "                    #print(f'     Test error = {error.gamma(classify)[0]}')\n",
    "                    #print(f'     Test disparity = {disparity.gamma(classify).max()}')\n",
    "                    disp_mitigated_test += [disparity.gamma(classify).max()]\n",
    "\n",
    "                    # Alternative fidelity of intervention model to no intervention model\n",
    "                    alt_fid_train = accuracy_score(classifier_mitigated_bias.predict(X_bias_true, sensitive_features = df_sens),classifier_bias.predict(X_bias_true))\n",
    "                    alt_fid_test = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_bias.predict(X_test))\n",
    "                    #print(f'Alternative fidelity of intervention model to no intervention model: train = {alt_fid_train}, test = {alt_fid_test}')\n",
    "                else:\n",
    "                    disp_mitigated_train += [np.nan]\n",
    "                    disp_mitigated_test += [np.nan]\n",
    "\n",
    "#                     acc_mitigated_train += [np.nan]\n",
    "#                     acc_mitigated_test += [np.nan]\n",
    "\n",
    "            else:\n",
    "                classifier_mitigated_bias = clone(classifier_bias)\n",
    "                classifier_mitigated_bias.fit(X_bias_true, y_bias_true)\n",
    "                \n",
    "                disp_mitigated_train += [0]\n",
    "                disp_mitigated_test += [0]\n",
    "                \n",
    "#                 acc_mitigated_train += [0]\n",
    "#                 acc_mitigated_test += [0]\n",
    "                \n",
    "                # NOTE: disparities are the same as for classifier_bias\n",
    "\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                else:\n",
    "                    # Fidelity in this step\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "                    #print(f'Test set fidelity of learned BO classifier and mitigated_bias_classifier: {fid}')\n",
    "                    fid = accuracy_score(classifier_mitigated_bias.predict(X_test),exact_bo_labels_test)\n",
    "                    #print(f'Test set fidelity of exact BO classifier and mitigated biased classifier: {fid}')\n",
    "                \n",
    "            fid = accuracy_score(classifier_bias.predict(X_test),classifier_b.predict(X_test))\n",
    "            #print(f'Test set fidelity of learned BO classifier and biased classifier: {fid}')\n",
    "            \n",
    "            if not is_empty:\n",
    "                if apply_fairness:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj, sensitive_features = sens_attr_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min, sensitive_features = sens_attr_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test, sensitive_features = sens_attr_test), classifier_b.predict(X_test))]\n",
    "                else:\n",
    "                    # fidelity check\n",
    "                    test_maj += [accuracy_score(classifier_mitigated_bias.predict(X_test_maj), classifier_b.predict(X_test_maj))]\n",
    "                    #print(test_maj)\n",
    "                    test_min += [accuracy_score(classifier_mitigated_bias.predict(X_test_min), classifier_b.predict(X_test_min))]\n",
    "                    #print(test_min)\n",
    "                    total += [accuracy_score(classifier_mitigated_bias.predict(X_test), classifier_b.predict(X_test))]\n",
    "            else:\n",
    "                test_maj += [np.nan]\n",
    "                test_min += [np.nan]\n",
    "                total += [np.nan]\n",
    "                \n",
    "            if verbose:\n",
    "                #print(\"Finished Iteration: \", count)\n",
    "                count +=1\n",
    "        \n",
    "        #print(f'Fidelity test maj: {test_maj}')\n",
    "        #print(f'Fidelity test min: {test_maj}')\n",
    "        \n",
    "        total_fidel_maj.append(test_maj)\n",
    "        total_fidel_min.append(test_min)\n",
    "        total_fidel.append(total)\n",
    "        \n",
    "        total_disp_bias_train.append(disp_bias_train)\n",
    "        total_disp_bo_train.append(disp_bo_train)\n",
    "        total_disp_mitigated_train.append(disp_mitigated_train)\n",
    "\n",
    "        total_disp_bias_test.append(disp_bias_test)\n",
    "        total_disp_bo_test.append(disp_bo_test)\n",
    "        total_disp_mitigated_test.append(disp_mitigated_test)\n",
    "        \n",
    "#         total_acc_bias_train.append(acc_bias_train)\n",
    "#         total_acc_bo_train.append(acc_bo_train)\n",
    "#         total_acc_mitigated_train.append(acc_mitigated_train)\n",
    "\n",
    "#         total_acc_bias_test.append(acc_bias_test)\n",
    "#         total_acc_bo_test.append(acc_bo_test)\n",
    "#         total_acc_mitigated_test.append(acc_mitigated_test)\n",
    "        \n",
    "        if verbose:\n",
    "                print(\"Finished Total Iteration: \", i+1)\n",
    "    \n",
    "    mean_fidel_maj = remove_nan(total_fidel_maj)\n",
    "    mean_fidel_min = remove_nan(total_fidel_min)\n",
    "    mean_fidel = remove_nan(total_fidel)\n",
    "    \n",
    "    mean_disp_bias_train = remove_nan(total_disp_bias_train)\n",
    "    mean_disp_bo_train = remove_nan(total_disp_bo_train)\n",
    "    mean_disp_mitigated_train = remove_nan(total_disp_mitigated_train)\n",
    "    \n",
    "    mean_disp_bias_test = remove_nan(total_disp_bias_test)\n",
    "    mean_disp_bo_test = remove_nan(total_disp_bo_test)\n",
    "    mean_disp_mitigated_test = remove_nan(total_disp_mitigated_test)\n",
    "    \n",
    "#     mean_acc_bias_train = remove_nan(total_acc_bias_train)\n",
    "#     mean_acc_bo_train = remove_nan(total_acc_bo_train)\n",
    "#     mean_acc_mitigated_train = remove_nan(total_acc_mitigated_train)\n",
    "    \n",
    "#     mean_acc_bias_test = remove_nan(total_acc_bias_test)\n",
    "#     mean_acc_bo_test = remove_nan(total_acc_bo_test)\n",
    "#     mean_acc_mitigated_test = remove_nan(total_acc_mitigated_test)\n",
    "    \n",
    "    y_err_fidel_maj = remove_nan_std(total_fidel_maj)\n",
    "    y_err_fidel_min = remove_nan_std(total_fidel_min)\n",
    "    y_err_fidel = remove_nan_std(total_fidel)\n",
    "    \n",
    "    \n",
    "    df_disp = pd.DataFrame({\"Biased Train\" : mean_disp_bias_train,\n",
    "                       \"BO Train\" : mean_disp_bo_train,\n",
    "                       \"Mitigated Train\" : mean_disp_mitigated_train,\n",
    "                       \"Biased Test\" : mean_disp_bias_test,\n",
    "                       \"BO Test\" : mean_disp_bo_test,\n",
    "                       \"Mitigated Test\" : mean_disp_mitigated_test})\n",
    "    \n",
    "#     df_acc = pd.DataFrame({\"Biased Train\" : mean_acc_bias_train,\n",
    "#                        \"BO Train\" : mean_acc_bo_train,\n",
    "#                        \"Mitigated Train\" : mean_acc_mitigated_train,\n",
    "#                        \"Biased Test\" : mean_acc_bias_test,\n",
    "#                        \"BO Test\" : mean_acc_bo_test,\n",
    "#                        \"Mitigated Test\" : mean_acc_mitigated_test})\n",
    "   \n",
    "    return bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df_disp#, df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eae1cef5-b091-4681-bf4f-515c6e17de94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff:  -0.49295833333333333\n",
      "Total Deleted:  1159 \t % Deleted:  0.3973260198834419\n",
      "Diff:  -0.40304166666666663\n",
      "Total Deleted:  1234 \t % Deleted:  0.4055208675649031\n",
      "Diff:  -0.2975\n",
      "Total Deleted:  1177 \t % Deleted:  0.39142001995344194\n",
      "Diff:  -0.20387500000000003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ef1623bc481b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mbias_amts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_maj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_err_fidel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdiff_base_rates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disp_diff_base_rates.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-a29b5ded3e12>\u001b[0m in \u001b[0;36mdiff_base_rates\u001b[0;34m(r, n, verbose, num_iters)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mexact_bo_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome_continuous\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mexact_bo_labels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexact_bo_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mexact_bo_labels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexact_bo_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_synthetic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "eta = 0.4\n",
    "n = 30000\n",
    "r = 0.2\n",
    "num_iters = 5\n",
    "\n",
    "bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel, df = \\\n",
    "diff_base_rates(r = r, n = n, verbose=True, num_iters=num_iters)\n",
    "\n",
    "df.to_csv('disp_diff_base_rates.csv', index = True)\n",
    "df_res = pd.DataFrame(np.array([bias_amts, mean_fidel_maj, mean_fidel_min, mean_fidel, y_err_fidel_maj, y_err_fidel_min, y_err_fidel]).T, columns=['bias_amts', 'mean_fidel_maj', 'mean_fidel_min', 'mean_fidel', 'y_err_fidel_maj', 'y_err_fidel_min', 'y_err_fidel'])\n",
    "df_res.to_csv(f'fid_diff_base_rates.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3e06588-c835-4980-bfb0-1699dc39482c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bias_amts = [-0.5, -0.4, -0.3, -0.2, -0.1, 0, .1, .2, .3, .4, .5]\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.errorbar(bias_amts, mean_fidel_maj, yerr = y_err_fidel_maj, label = 'Fidelity Majority', color = \"red\")\n",
    "plt.errorbar(bias_amts, mean_fidel_min, yerr = y_err_fidel_min, label = 'Fidelity Minority', color = \"green\")\n",
    "plt.xlabel(\"Difference in Proportion of Positive Labels (Majority - Minority)\")\n",
    "plt.ylabel(\"Fidelity\")\n",
    "#plt.xlim(-0.4, 0.5)\n",
    "#plt.ylim(0.9, 1)\n",
    "#plt.xlim(1.05, -0.05)\n",
    "plt.legend()\n",
    "plt.title(\"Fidelity Plot\")\n",
    "#plt.savefig('diff_base_rates.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
